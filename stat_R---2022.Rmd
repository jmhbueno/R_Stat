---
title: "Estatística no R"
author: "Maurício Bueno"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

Esta disciplina tem o objetivo de instrumentalizar o aluno para a realização das análises estatísticas mais empregadas em pesquisas em psicologia, no ambiente de programação R.
Inicialmente, vamos carregar e ativar os pacotes que iremos utilizar na disciplina.

# Carregamento dos pacotes

```{r}
# if(!require(tidyverse)) install.packages("tidyverse")
# if(!require(psych)) install.packages("psych")
# if(!require(knitr)) install.packages("knitr")
# if(!require(kableExtra)) install.packages("kableExtra")
# if(!require(expss)) install.packages("expss")
# if(!require(janitor)) install.packages("janitor")
# if(!require(pander)) install.packages('pander')
# if(!require(arsenal)) install.packages('arsenal')
# if(!require(moments)) install.packages('moments')
# if(!require(readr)) install.packages('moments')
# if(!require(readxl)) install.packages('readxl')
# if(!require(descr)) install.packages("descr")
# if(!require(rcompanion)) install.packages("rcompanion")
# if(!require(rstatix)) install.packages("rstatix")

# install.packages("Rcpp")
# Ativação dos pacotes ====

library(tidyverse)
library(psych)
library(arsenal)
# library(rstatix)
# library(GPArotation)
library(corrplot)
library(janitor)
library(pander)
library(knitr)
# library(kableExtra)
# library(expss)
# library(readxl)
# library(readr)
```

# Importar banco de dados

Inicialmente vamos trabalhar com o banco de dados `dataset_mapfre.csv`, clique [aqui](https://docs.google.com/spreadsheets/d/1G0lQKeU0atMk3Q4wO5zz4HdvReRxKS68vx_Q0WbB37A/edit?usp=sharing) para baixá-lo.
Salve-o como um dataframe chamado `dataset`.

Dica: Utilize a função `read.csv`, cujo argumento `stringsAsFactors=TRUE` já salva as variáveis categóricas como fator.

Esse banco de dados se refere ao artigo "[Sintomas de depressão e ansiedade em uma amostra representativa de universitários espanhóis, portugueses e brasileiros](https://drive.google.com/file/d/1qa0iCDm2DRvh3M6a2k7ENGahceDAlPIg/view?usp=sharing)".
Sugere-se a leitura desse artigo para a compreensão dos dados.

```{r}
dataset <- read.csv("dataset_mapfre.csv",encoding="UTF-8",stringsAsFactors=TRUE)

# OBS: Para que este comando funcione, é necessário que o arquivo csv esteja no diretório de trabalho do R.

# Observar o banco de dados
glimpse(dataset)
```

# Estatísticas

Este curso está didaticamente dividido em três tipos de análises estatísticas:

1.  Estatísticas descritivas, que incluem as medidas de frequência, de tendência central e de dispersão.
2.  Estatísticas que ajudam a compreender associação entre variáveis: qui-quadrado, correlação, regressão e análise fatorial.
3.  Efeitos de grupo em outras variáveis: t-teste e análises de variância.

As próximas seções apresentam recursos para a realização dessas análises.

# Estatísticas descritivas de frequência

A forma mais simples de descrever algo quantitativamente é contando o número de ocorrências.
Por exemplo, podemos descrever uma amostra quanto à escolaridade, contando as ocorrências de ensino fundamental, ensino médio e ensino superior.
As formas mais comuns para sumariar esses dados de forma mais amigável para o leitor é através de **tabelas** e **gráficos**.
Vamos ver essas formas a seguir.

## Tabelas de frequência com a função `table()`

```{r}
# Tabulando dados

table(dataset$country)
table1 <- table(dataset$country, dataset$sex)
table1 %>% pander()
table1 %>% kable()

# Tabulação em dataframe com porcentagens
table(dataset$country) %>% 
  as.data.frame() %>% 
  mutate("%" = Freq*100/sum(Freq)) %>% 
  pander()

table(dataset$country, dataset$sex) %>% 
  as.data.frame() %>% 
  mutate("%" = Freq*100/sum(Freq)) %>% 
  pander()

table(dataset$country, dataset$sex, dataset$bai_class) %>% 
  as.data.frame() %>% 
  mutate("%" = Freq*100/sum(Freq)) %>% 
  pander()
```

## Tabelas de frequência com a função `count()`

```{r}
# Contar uma variável
dataset %>% 
  count(sex) %>% 
  mutate("%" = n*100/sum(n)) %>%
  pander()

# Contar uma variável x em função de uma y, com totalização integral.

dataset %>% 
  count(sex,country) %>% 
  mutate("%" = n*100/sum(n)) %>%
  pander()

# Contar uma variável x em função de outra y, com totalização pelas categorias de x. 

dataset %>% 
  filter(!is.na(sex)) %>% 
  group_by(sex) %>% 
  count(country) %>% 
  mutate(porc = n/sum(n)*100) %>% 
  pander()
```

## Tabelas de frequência com o pacote `janitor`

```{r}
# install.packages("janitor")
# library(janitor)

# usando a função tabyl() do pacote janitor
# contar quantas pessoas de cada país.

dataset %>%             # pegar o dataframe dataset
  tabyl(country) %>%    # use a função tabyl para tabular as categorias de país
  pander()              # utilize o pander para fazer a tabela

dataset %>%             # pegar o dataframe dataset
  tabyl(country) %>%    # use a função tabyl para tabular as categorias de país
  adorn_totals() %>%    # acrescente uma linha com os totais
  pander()              # utilize o pander para fazer a tabela

dataset %>%             # pegar o dataframe dataset
  tabyl(country) %>%    # use a função tabyl para tabular as categorias de país
  adorn_totals() %>%    # acrescente uma linha com os totais
  adorn_pct_formatting(digits = 1) %>% 
  pander()              # utilize o pander para fazer a tabela

# contar por gênero e país (retirando NAs)
dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(sex,country) %>% 
  adorn_totals() %>% 
  pander()

dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(sex,country) %>% 
  adorn_totals(c("row","col")) %>% 
  pander()

dataset %>% 
  drop_na(sex) %>%        # outra forma de eliminar os NAs
  tabyl(sex,country) %>% 
  adorn_totals(c("row","col")) %>% 
  pander()

dataset %>% 
  tabyl(sex,country,show_na = FALSE) %>% # eliminar NAs com argumento do próprio janitor
  adorn_totals(c("row","col")) %>% 
  pander()

# contar por gênero e país, acrescentando funções
dataset %>% 
  tabyl(country,sex, show_na = FALSE) %>%           # função de tabulação do janitor
  adorn_totals(c("row","col")) %>% # adiciona o N
  adorn_percentages("all") %>%     # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(
    rounding = "half up",          # arredondar do cinco pra cima
    digits = 0) %>%                # número de casas decimais
  adorn_ns() %>%                   # mostra N e % juntas
  pander()                         # melhora a visualização dos dados.

# adição de um qui-quadrado para a distribuição
# para rodar essa análise tem que tirar os totais.

dataset %>%
  filter(!is.na(sex)) %>%
  tabyl(country,sex) %>%           # função de tabulação do janitor
  adorn_totals(c("row","col")) %>% # adiciona o N
  chisq.test()
  # pander()                         # melhora a visualização dos dados.
```

## Gráficos de frequência com o pacote `ggplot2`

### Gráficos de barras

```{r}

# Gráfico mais simples possível (contagem simples)
ggplot(dataset, aes(x = country)) + 
  geom_bar(color = "black", fill = "dodgerblue")

# Gráfico de barras mais complexo (4)

## Camada 1 - gráfico de barras com algumas melhorias visuais

ggplot(data = dataset,             # base de dados
       mapping = aes(x = country,  # informação que vai no eixo x
                     y = ..prop.., # informação que vai no eixo y: forma de indicar que é a proporção
                     group = 1)) + 
  geom_bar(stat = "count",         # definir que a estatística parte da contagem
           fill = "dodgerblue4",   # cor das barras
           width = .5,             # espessura das barras
           color = "black") +      # cor da borda das barras

## Camada 2 - colocar eixo y em porcentagem
    scale_y_continuous(labels = scales::percent_format()) +

## Camada 3 - colocar o valor das porcentagens nas barras
  geom_text(aes(label = scales::percent(..prop..),
                y = ..prop..),
            stat = "count", 
            color = "white",
            size = 5, 
            position = position_stack(vjust = 0.5)) +
  
## Camada 4 - Titulos, labels
    labs(x = "País",
       y = "Porcentagem",
       title = "Número de participantes por país",
       subtitle = "Brasil, Portugal e Espanha",
       caption = "Núcleo de Estudos em Avaliação Psicológica - NEAP")

# Gráfico de barras empilhadas (utilizando o geom_col)
# OBS.: O geom_col é parecido com o geom_bar, mas o primeiro só aceita dados diretos.
# Por isso, nesse caso, é preciso preparar o dataframe antes.

## Preparação do data frame
dataset %>% 
  count(country) %>% 
  mutate(pct = n/sum(n)) %>% 
## Camada 1
  ggplot(.,aes(x = "", 
               y = pct, 
               fill = country)) + # se o argumento fill for colocado dentro de aes, sai uma cor por barra 
  geom_col(color = "black") +
## Camada 2
  geom_text(aes(label = scales::percent(round(pct,3))),
            position = position_stack(vjust = 0.5)) + 
## Camada 3
  labs(title = "Proporção de participantes por país")
```

### Gráficos de pizza

```{r}
# é um gráfico de barras empilhadas transformado em polar

## preparação dos dados
dataset %>% 
  count(country) %>% 
  mutate(pct = n/sum(n)) %>%
# Camada 1
  ggplot(.,aes(x = "", y = pct, fill = country)) + 
  geom_col(color = "black") + 
# Camada 2
  geom_text(aes(label = scales::percent(round(pct,3))),
            position = position_stack(vjust = 0.5)) + 
# Camada 3
  coord_polar(theta = "y") +
# Camada 4 
  labs(title = "Proporção de participantes em cada país") + 
   xlab(NULL) + 
   ylab(NULL)

```

### Gráficos de linhas

```{r}
# Contar categorias dentro de uma variável (nível de depressão)

dataset %>%
  drop_na(bdi_class) %>% 
  ggplot() +
  geom_line(aes(x = bdi_class, group = 1), stat = "count", size = 1.2) +
  labs(title = "Classificações de Depressão - Frequências",
       x = "Classificação",
       y = "Frequências")

# Misturando variáveis (frequência de classificações por gênero)

## preparação dos dados
dataset %>%
  drop_na(bdi_class,sex) %>% 
  group_by(sex) %>% 
  count(bdi_class,sex) %>%
  mutate(porc = n*100/(sum(n))) %>% 
## camada 1
  ggplot() +
  geom_line(aes(x = bdi_class, 
                y = porc, 
                group = sex, 
                color = sex), 
            size = 1.0) +
## camada 2
  labs(title = "Classificações de Depressão por gênero",
       x = "Classificação",
       y = "Frequências")
```

# Estatísticas descritivas de tendência central e de dispersão

A descrição dos dados geralmente é realizada pelas seguintes estatísticas: Média, desvio padrão, mediana, amplitude, mínimo, máximo, assimetria e curtose.
Algumas dessas análises (média, desvio padrão e mediana) informam sobre o ponto central da distribuição das medidas.
Outras, como o desvio padrão, a amplitude, a assimetria e a curtose informam sobre a forma como os valores se afastam do ponto central.

Aqui, é importante atentar para a **distribuição normal**, cujas características são apresentadas na Figura abaixo.

```{r echo=FALSE}
distnorm <- rnorm(100000, mean = 10, sd = 2)
hist(distnorm,
     col = "lightblue",
     main = "Distribuição Normal",
     freq = F,
     xlab = "Escores",
     ylab = "Frequência",
     breaks = 21)
curve(dnorm(x, mean = mean(distnorm), sd = sd(distnorm)), add = TRUE)

# distnorm1 <- data.frame(escores=rnorm(100000,10,2))
# 
# ggplot(distnorm1, aes(x = escores)) + 
#   geom_histogram(aes(y = ..density..),
#                  fill = "pink",
#                  color = "black",
#                  alpha = 1,
#                  bins = 25) +
#   stat_function(fun = dnorm, args = list(mean = mean(distnorm1$escores), sd = sd(distnorm1$escores))) + 
#   labs(title = "Distribuição Normal",
#        x = "Escores",
#        y = "Densidade")
```

### Medidas de tendência central

```{r}
## mean()
mean(dataset$age, na.rm = TRUE)

## sd()
sd(dataset$age, na.rm = TRUE)

## median()
median(dataset$age, na.rm = TRUE)
```

### Medidas de dispersão

```{r}
## min()
min(dataset$age, na.rm = TRUE)

## max()
max(dataset$age, na.rm = TRUE)

## range()
range(dataset$age, na.rm = TRUE)

## skewness()
# moments::skewness(dataset$age, na.rm = TRUE) # pacote moments 
skew(dataset$age, na.rm = TRUE)              # pacote psych

## kurtosis()
# moments::kurtosis(dataset$age, na.rm = TRUE) # pacote moments
kurtosi(dataset$age, na.rm = TRUE)           # pacote psych

```

## Funções que sumariam dados

```{r}
# summary() {base}
dataset %>% select(age) %>% summary()

# summarise() {tidyverse}
dataset %>% 
  drop_na(sex,age,bai_sum,bdi_sum) %>%
  group_by(sex) %>% 
  summarise(idade = mean(age),
            BAI = mean(bai_sum),
            BDI = mean(bdi_sum))

# describe() {psych}
describe(dataset$age, na.rm = TRUE) %>% pander()
describe(dataset$age, na.rm = TRUE) %>% pander(format = "markdown")

# tableby() {arsenal}
tableby(country ~ bdi_sum + bai_sum, # calcule as descritivas de bdi e bai por country 
        test = FALSE,                # se FALSE,  não faz teste de significância 
        data = dataset) %>%          # especificar base de dados
  summary(text=TRUE)                 # tem que colocar text=TRUE senão aparecem uns códigos estranhos porque o R entende o espaço como código. Assim a tabela fica bacaninha.

## mesma função mas para a variável sexo.
tableby(sex ~ bdi_sum + bai_sum,
        test = FALSE,
        data = dataset) %>% 
  summary(text=TRUE)

## Pode descrever apenas uma variável em função de sexo
tableby(sex ~ age, data = dataset) %>% summary(text = TRUE)

## Pode descrever somenta a variável contínua sem ser em função de alguma outra variável.
tableby( ~ age + bdi_sum + bai_sum, data = dataset) %>% summary(text = TRUE)

## Também pode dar as médias em função do sexo, estratificado por país
tableby(sex ~ age + bdi_sum + bai_sum, data = dataset, strata = country) %>% summary(text = TRUE)

## ou o contrário
tableby(country ~ age + bdi_sum + bai_sum, data = dataset, strata = sex) %>% summary(text = TRUE)

## Interação entre variáveis nominais

tableby(interaction(sex, country) ~ bdi_sum + bai_sum,
        test = FALSE,
        data = dataset) %>% 
  summary(text = TRUE)
```

## Gráficos de medidas de tendência central e de dispersão

### Gráficos de barras

```{r}
# Gráfico de barras - Gráfico básico

ggplot() +
    # Camada 1 - Barras
    geom_bar(data = dataset,
           mapping = aes(x = country,
                         y = bai_sum),
           stat = "summary",
           fun = mean,
           na.rm = TRUE)

# Gráfico de barras básico, com embelezamento

ggplot() +
    # Camada 1 - Barras com embelezamento
    geom_bar(data = dataset,
           mapping = aes(x = country,
                         y = bai_sum),
           stat = "summary",
           fun = mean,
           na.rm = TRUE,
           fill = "dodgerblue",
           color = "black")


# Gráfico de barras completo: Básico + Outros geoms (barra de erros e texto)

médias_BAI <- # dataframe com as informações que eu vou inserir na camada 2 do gráfico
dataset %>% group_by(country) %>% summarise(mean = mean(bai_sum, na.rm = TRUE))

ggplot() +
  # Camada 1 - Barras com embelezamento
  geom_bar(data = dataset,
           mapping = aes(x = country,
                         y = bai_sum),
           stat = "summary",
           fun = mean,
           na.rm = TRUE,
           fill = "dodgerblue",
           color = "black") +
  # Camada 2 - Barra de Erro
  stat_summary(data = dataset, 
               mapping = aes(x=country, y=bai_sum),
               geom = "errorbar",
               fun.data = mean_se,
               width = 0.5) +
  # Camada 3 - Texto (valor das médias dentro das barras)
  geom_text(data = médias_BAI,
            mapping = aes(x = country,
                          y = mean,
                          label = format(mean,digits = 1,nsmall = 1)),
            fontface = "bold", size = 5, vjust = 3)

# Gráfico de barras (step3): Básico + Texto + Complementos (lables, themes e coord)

ggplot() +
  # Camada 1 - Barras com embelezamento
  geom_bar(data = dataset,
           mapping = aes(x = country,
                         y = bai_sum),
           stat = "summary",
           fun = mean,
           na.rm = TRUE,
           fill = "dodgerblue",
           color = "black") +
  # Camada 2 - Barra de Erro
  stat_summary(data = dataset, mapping = aes(x=country, y=bai_sum),
               geom = "errorbar",fun.data = mean_se,width = 0.5) +
  # Camada 3 - Texto (valor das médias dentro das barras)
  geom_text(data = médias_BAI,
            mapping = aes(x = country,
                          y = mean,
                          label = format(mean,digits = 1,nsmall = 1)),
            fontface = "bold", size = 5, vjust = 3) +
  # Camada 4 - Labels (título, subtítulo, eixos, caption, theme, coord)
  coord_cartesian(ylim = c(0,10)) +   # mudar escala do eixo y
  # coord_flip() + (se ligar, é necessário ajustar vjust e hjust)
  labs(title = "Média de Ansiedade por país",
       subtitle = "Ansidade medida pelo BAI",
       x = "País",
       y = "Média de Ansiedade (BAI)",
       caption = "Núcleo de Estudos em Avaliação Psicológica") + 
  theme_gray()

# colorindo por país
# tem que colocar o fill dentro do aes
ggplot() +
  # Camada 1 - Barras com embelezamento
  geom_bar(data = dataset,
           mapping = aes(x = country,
                         y = bai_sum,
           fill = country),
           stat = "summary",
           fun = mean,
           na.rm = TRUE,
           color = "black") +
  # Camada 2 - Barras de erro
  stat_summary(data = dataset, 
               mapping = aes(x=country, y=bai_sum),
               geom = "errorbar",
               fun.data = mean_se,width = 0.5,
               na.rm = TRUE) +
  # Camada 3 - Texto (valor das médias dentro das barras)
  geom_text(data = médias_BAI,
            mapping = aes(x = country,
                          y = mean,
                          label = format(mean,digits = 1,nsmall = 1)),
            fontface = "bold", size = 5, vjust = 3) + # mudar vjust e hjust
  # Camada 4 - Labels (título, subtítulo, eixos, caption, theme, coord)
  coord_cartesian(ylim = c(0,10)) +   # mudar escala do eixo y
  # coord_flip() +                      # gráfico horizontal
  labs(title = "Média de Ansiedade por país",
       subtitle = "Ansidade medida pelo BAI",
       x = "País",
       y = "Média de Ansiedade (BAI)",
       caption = "Núcleo de Estudos em Avaliação Psicológica") + 
  theme_gray()
```

### Boxplot

```{r}
# Gráfico básico
ggplot(data = dataset, 
       mapping = aes(x = country, y = bai_sum)) +
  geom_boxplot(fill = "violet") +
  labs(title = "Boxplots BAI por país",
       x = "Países",
       y = "Ansiedade_BAI")

# Gráfico mais completo 

## Passo 1 - Criação de um dataframe com informações sobre a mediana
median_boxplot <- 
  dataset %>% 
  group_by(country) %>% 
  summarise(mediana = median(bai_sum, na.rm = TRUE))

## Gráfico
### camada 1
ggplot() +
  geom_boxplot(data = dataset, 
               mapping = aes(x = country, y = bai_sum, fill = country),
               show.legend = FALSE, 
               na.rm = TRUE) +
### camada 2
  geom_text(data = median_boxplot,
            aes(x = country, 
                y = mediana,
                label = format(mediana, digits = 1, nsmall = 1)),
            fontface = "bold", size = 4, vjust = -.5) +
### camada 3  
  labs(title = "Boxplots BAI por país",
       x = "Países",
       y = "Ansiedade_BAI") +
### camada 4
  theme_bw()
```

### Gráfico de pontos

```{r}

# Gráfico simples
ggplot(dataset, aes(x = country, y = bai_sum)) +
  geom_point(stat = "summary",fun = "mean",na.rm = TRUE)

## Outra forma de construir o "gráfico simples"
ggplot(dataset, aes(x = country, y = bai_sum)) +
  stat_summary(geom = "point", fun = "mean")

# "Gráfico simples" + Barra de erro

ggplot(dataset,aes(x = country, y = bai_sum)) +
  geom_point(stat = "summary", fun = "mean", size = 3) +
  geom_errorbar(stat = "summary", fun.data = "mean_se", width = 0.3)

# "Gráfico simples" + Barra de erro + Ajuste das dimensões
ggplot(dataset,aes(x = country, y = bai_sum)) +
  geom_point(stat = "summary", fun = "mean", na.rm = TRUE) +
  geom_errorbar(stat = "summary", fun.data = "mean_se", width = 0.3) + 
  coord_cartesian(ylim = c(0,12))

## install.packages("pacman")
pacman::p_load(ggpubr) # ggpubr é um pacote que adiciona algumas funções ao ggplot
                       # com isso fica possível usar a função mean_ci
                       # para calcular intervalo de confiança.

# OBS: a função p_load do pacote pacman verifica se um pacote está instalado e instala se for necessário.

### Barrinha de intervalo de confiança
ggplot(dataset,aes(x = country, y = bai_sum)) +
  geom_point(stat = "summary", fun = "mean", na.rm = TRUE) +
  geom_errorbar(stat = "summary", fun.data = "mean_ci", width = 0.3, na.rm = TRUE) + 
  coord_cartesian(ylim = c(5,12))

### Barrinha de desvio padrão
ggplot(dataset,aes(x = country, y = bai_sum)) +
  geom_point(stat = "summary", fun = "mean", na.rm = TRUE) +
  geom_errorbar(stat = "summary", fun.data = "mean_sd", width = 0.3, na.rm = TRUE) + 
  coord_cartesian(ylim = c(0,20))
```

# Análises de associação entre variáveis

Muitas vezes, o pesquisador está interessado no estudo ou análise de relações entre variáveis.
Nesses casos, ele recorrerá a estatísticas como o teste de qui-quadrado (caso tenha variáveis do tipo nominal ou categórica), coeficiente de correlação de Pearson ou regressão linear, entre outras, quando as variáveis forem contínuas.

## Testes de Qui-Quadrado

O teste de qui-quadrado é uma medida de associação entre variáveis categóricas, das quais só temos a frequência de ocorrência.
Existem três tipos de testes de qui-quadrado:

-   de aderência: quando se deseja verificar as distribuições de probabilidades de cada categoria de uma variável em relação a um valor teórico esperado.

-   de homogeneidade: quando se deseja verificar se as distribuições das categorias são as mesmas para diferentes subpopulações de interesse.

-   de independência: verficiar se duas variáveis categóricas são independentes

Neste caso, vamos fazer uma análise de qui-quadrado de independência, a mais comumumente utilizada, para verificar se há uma associação entre país e sexo dos participantes do banco de dados dataset.
O primeiro passo para isso é montar uma tabela de contingência.

### Tabela de Contingência

Nesse caso, vamos usar a função da base `table()` para gerar uma tabela 2 x 3, duas linhas e três colunas, em que as linhas representarão os sexos masculino e feminino, e as colunas representarão os países: Brasil, Portugal e Espanha.

```{r}
tabcont_sex_country <- table(dataset$sex,     # linhas
                             dataset$country) # colunas
```

O próximo passo é realizar a análise de qui-quadrado em si.

### Análise de qui-quadrado.

```{r}
# É bom salvá-la em um objeto porque tem mais informações do que as que são mostradas na análise.

options(scipen = 999) # função para tirar a notação científica de potência.

# Qui-quadrado
chi_sex_country <- chisq.test(tabcont_sex_country)
```

Nesse caso, o X^2^ foi de 48,458, para 2 graus de liberdade, e o valor de p foi igual a 3.003e-11 (lê-se 3.003 x 10^-11^).
Ou seja, o qui-quadrado foi estatisticamente significativo, indicando que os participantes dos sexos masculino e feminino **não foram** distribuídos homogeneamente dentro dos países.Isso poderia ser relatado da seguinte forma:

*Foi realizada uma análise de qui-quadrado para verificar se havia homogeneidade na distribuição dos sexos masculino e feminino entre os participantes de cada país (Brasil, Portugla e Espanha). Observou-se que a distribuição não foi homogênea (X^2^ = 48,458; gl = 2, p-valor = 3,003e-11) e que a falta de homogeneidade se deve aos participantes espanhois, cuja porcentagem de mulheres e mais elevada do que a de homens. Portugal e Brasil apresentaram porcentagens bem parecidas quanto a distribuição por gênero.*

### Representação em tabela

```{r}
dataset %>% 
  tabyl(sex,country,show_na = FALSE) %>%     # função de tabulação do janitor
  adorn_totals(c("row","col")) %>%           # adiciona o N
  adorn_percentages("col") %>%               # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(                
    rounding = "half up",                    # arredondar do cinco pra cima
    digits = 0) %>%                          # número de casas decimais
  adorn_ns() %>%                             # mostra N e % juntas
  pander()                                   # melhora a visualização dos dados.
```

Pode-se observar que as distribuições de Brasil e Portugal são muito próximas, mas a da Espanha é bastante diferente, o que deve estar produzindo a significância estatística.

### Representação gráfica

```{r}
ggplot(dataset, aes(x = country, fill = sex)) +
  geom_bar(position = "fill") +
  coord_flip() +
  labs(title = "Proporção Sexo x País",
       x = "País", 
       y = "Proporção", 
       fill = "Sex")
```

## Coeficientes de correlação: Pearson, Spearman e Kendall

Quando o interesse do pesquisador é investigar o grau de associação entre variáveis, ele pode empregar o Coeficiente de Correlação de Pearson.
Os resultados dessa análise podem variar de -1 a 1.
Resultados positivos revelam associação diretamente proporcional entre as variáveis, resultados negativos revelam associação inversamente proporcional entre as variáveis e resultados próximos de zero indicam que não há associação entre as variáveis.

Quando os dados apresentam distribuição normal, usamos o coeficiente de correlação de Pearson.
Para dados que não apresentam essa distribuição, usamos a correlação de Kendal ou Spearman.
Para isso, vamos usar a função `corrplot()` do pacote `corrplot`.
Portanto, é necessário instalar ( `install.packages("corrplot")`) e ativar (`library(corrplot)`) esse pacote.

### Matriz de correlações

```{r}
# matriz completa (correlações entre todas as variáveis)
matriz_comp <- corr.test(dataset[,c(3,89,92)])

## Visualização dos resultados
matriz_comp

## Visualização somente das correlações
matriz_comp$r

# matriz parcial (correlações de ansiedade/depressão com idade)
matriz_parc <- corr.test(dataset[,c(89,92)],dataset[,3], method = "pearson")

## Visualização dos resultados
matriz_parc

## Visualização somente das correlações
matriz_parc$r
```

Os resultados são apresentados em três matrizes.
A primeira com os coeficientes de correlação, a segunda com o número de participantes empregado para o cálculo dos coeficientes, e a terceira com os p-values.
Para um coeficiente de correlação ser estatisticamente significativo, o p-value deve ser menor que 0,05, pois isso indica que o valor do coeficiente de correlação obtido seria muito raro em um banco de dados aleatórios.

Na matriz completa, nota-se que as correlações de bdi_sum e bai_sum com idade foram próximas de zero e com p-vlaues de 0,43 e 0,06, respectivamente, indicando que não há associação entre de ansiedade e depressão com idade.
Mas a correlação entre bdi_sum e bai_sum foi de 0,60 com p-value igual a 0,00 (nesses casos, relata-se p \< 0,01).
Exemplo de relato:

*Observou-se que houve correlação positiva e estatisticamente significativa entre ansiedade e depressão (r = 0,60; p \< 0,01) e correlações negativas e não significativas de ansiedade (r = -0,04; p = 0,06) e depressão (r = -0.02, p = 0,43) com idade.*

### Representação gráfica das correlações

```{r}
# gráfico de dispersão de pontos

ggplot(dataset, aes(x=bdi_sum,y=bai_sum)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Depressão e Ansiedade", 
       x = "Depressão", 
       y = "Ansiedade") +
  theme_classic()

# adicionar informações sobre a curva de regressão

# summary(lm_ans_dep) # esse linear model foi rodado anteriormente


ggplot(dataset, aes(x=bdi_sum,y=bai_sum)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Depressão e Ansiedade", 
       x = "Depressão", 
       y = "Ansiedade") +
  theme_classic() + 
  annotate("text",x=20,y=65,label="Adjusted R-squared:  0.3596") + 
  annotate("text",x=20,y=60,label="bai_sum = 4.36700 + 0.57206*bdi_sum")
  

# matriz de correlações usando o corrplot
corrplot::corrplot(matriz_comp$r, 
                   method = "shade",
                   type = "lower",
                   order = "hclust",
                   addCoef.col = TRUE)

# opções de método: "circle", "square", "ellipse", "number", "shade", "color", "pie
# opções de tipo: "lower", "upper", "full"
# opção de ordem: "hclust"- organiza as correlações hierarquicamente
#                 "original" - ordem das variáveis no banco
#                 "AOE" - angular order of eigenvectors
#                 "alphabet" - ordem alfabética
```

## Regressão Linear Múltipla

A análise de regressão linear avança em relação ao coeficiente de correlação, por estabelecer QUANTO uma variável varia em função de outra.
Por exemplo, é possível predizer ansiedade a partir da depressão?
Quanto a ansiedade varia em função da depressão?

Então, nesse caso, teremos a ansiedade como variável dependente (aquela que se quer prever) e a depressão como independente (aquela que será a preditora).
Para verificar isso, usaremos a função `lm()` do pacote stats da base do R.
LM são as iniciais de linear model.

```{r}
mod_ans_dep <- lm(data = dataset,       # onde estão os dados
                  bai_sum ~ bdi_sum,    # depressão predizendo ansiedade
                  na.action = na.omit)  # ignorar NAs

# OBS.: Estamos salvando os resultados do modelo no objeto mod_ans_dep. Para ver o resultado, podemos usar a função summary()

summary(mod_ans_dep)
```

Há três tipos de resultados importantes na saída dessta análise:

1.  F-statistic: 1094 on 1 and 1946 DF, p-value: \< 2.2e-16

Essa é a última linha dos resultados, mas a primeira a ser observada.
A estatística F compara se a associação entre as duas variáveis consideradas (ansiedade e depressão) é significativamente diferente da associação entre duas variáveis aleatórias (cuja correlação costuma ser muito próxima de zero).
Portanto, se a estatística F for estatisticamente significativa (p-value \< 0,05), isso indica que pode ser possível descrever a variação de uma variável (ansiedade) em função da outra (depressão), porque provavelmente há associação entre ansiedade e depressão.

2.  Multiple R-squared: 0.3599, Adjusted R-squared: 0.3596

Indica a % de variância de ansiedade (variação entre as pessoas) que é explicada pela variância de depressão.
Há dois índices, o R-quadrado e o R-quadrado ajustado.
O segundo é ajustado para o número de variáveis preditoras que há no modelo e é mais adequado que o R-quadrado.

Nesse caso, utilizando o R-quadrado ajustado, o resultado indica que 35,96% da variância de ansiedade é explicada pela variância de depressão.

3.  Os coeficientes de regressão

Os coeficientes são os valores que entram na equação: $y_i = \alpha + \beta x_i + e_i$

Nesse caso, o $\alpha = 2,69295$ (intercepto) e $\beta = 0,62919$ .
Isso indica que, para predizer a pontuação em ansiedade de sujeito i, basta pegar sua pontuação em depressão, multiplicar por 0,62919 e somar 2,69295 e o erro de estimação desse sujeito (diferença entre o predito e o real).
Nota-se que o p-valor de bdi_sum foi estatísticamente significativo, com p = 2 .
10^-16^ , indicando que a cada ponto que depressão sobre, a ansiedade sobre 0,62919 pontos.

Exemplo de relato dos resultados: *Foi realizada uma análise de regressão para verificar a possibilidade de predizer ansiedade a partir da depressão. Observou-se que essa predição é viável (F=1094, DF = 1, p-value \< 2.2e-16), que ela explica 36% da variância total de ansiedade e que a cada aumento de um ponto em depressão, a pontuação em ansiedade tende a aumentar 0,63 pontos.*

A análise de regressão linear múltipla, é muito semelhante à simples.
Apenas envolvem mais de uma variável independente.
Vamos ver esse exemplo, com o banco de dados big_five, do qual vamos selecionar apenas os dados dos participantes brasileiros.
Para isso, no seu computador, copie o banco de dados `big_five` para o diretório em que está realizando estas análises.

```{r}
# importar o "big_five.rds" para dentro do R.
big_five <- readRDS("big_five.rds")

# selecionar somente os participantes brasileiros do df big_five.
big_five_BR <- big_five %>% filter(país == "BR")
```

Em seguida, gerar o modelo e sumariar os dados.

```{r}
# rodando a regressão (usando a função lm() do pacote stats (básico do R)
# lm vem de linear model
mod <- lm(idade ~ extr+neur+amab+cons+aber, # big-five predizendo idade
          data=big_five_BR,                 # onde estão os dados
          na.action = na.omit)              # ignorar NAs

## Interpretação do modelo
summary(mod)

# estatística F: comparação do modelo real com o modelo nulo (sem variáveis independentes). Então, só faz sentido usar o modelo real se ele for melhor que o modelo nulo. Para isso, o valor de p < 0,05.
# R-squared: porcentagem da variância que é explicada pelo modelo. O R-squared corrige pelo número de variáveis, o que permite comparar modelos com diferentes números de variáveis independentes. 
```

Reportando resultados: O modelo experimental é significativamente diferente de um modelo nulo (F = 6,768, gl = 169, p = 8,898 . 10^-6^), e foi capaz de explicar 14,2% da variância da idade por meio dos traços de extroversão e conscienciosidade.

```{r}
mod$coefficients %>% as.data.frame() %>% pander()
```

## Análise fatorial exploratória

A análise fatorial exploratório é um recurso estatístico complexo, que usa, na sua base, coeficientes de correlação (ou de covariância) e regressões, com o objetivo de identificar conjuntos de variáveis que se comportam de forma semelhante ao longo dos sujeitos.
Essas variáveis são, geralmente, itens de um teste.
Então, comportar-se de forma semelhante ao longo dos sujeitos quer dizer que esse grupo de variáveis (itens) apresentam magnitudes semelhantes no mesmo sujeito.
Por exemplo, um grupo de itens que é respondido com valores altos pelo sujeito s1, baixos pelo sujeito s2, médios pelo sujeito s3, e assim por diante....
não importa quem responda, as respostas são sempre coerentes entre si (baixas, médias ou altas).

Por essas características, é muito utilizada na construção de instrumentos de avaliação psicológica como um recurso para a investigação da **validade com base na estrutura interna**.

A realização de uma análise fatorial exploratória sguem alguns passos:

1.  Verificação das condições para a realização da análise fatorial
2.  Identificação do número de fatores a serem retidos na análise
3.  Extração dos fatores

Então, vamos ver uma fase por vez, usando o dataframe `big_five`.

#### Verificação das condições para a realização da análise fatorial

Geralmente, são empregados dois indicadores para essa finalidade: o índice de Kaizer-Meyer-Olkin (KMO) e o Teste de Esfericidade de Bartlett.

O KMO indica se há correlações suficientes para a realização da análise fatorial.
Pode variar de zero a 1 e **deve ser superior a 0,5** para que se possa prosseguir com a análise de forma adequada.

```{r}
big_five %>% select(9:58) %>% KMO()
```

O KMO total foi de 0,91, indicando haver condições suficientemente boas para o emprego da análise fatorial.

O Teste de esfericidade de Bartlett indica se a matriz de correlações é significativamente diferente de uma matriz identidade (uma matriz em que todos os valores da diagnonal são iguais a 1 e os demais são iguas a zero).
Ou seja, nesse caso, o qui-quadrado entre a matriz de dados experimentais e uma matriz de dados aleatórios.
Se p-valor \< 0,05, então a matriz é significativamente diferente de uma matriz identidade.

```{r}
big_five %>% select(9:58) %>% bartlett.test()
```

Nesse caso, o p-valor \< 2.2e-16 indica que a matriz de correlações é significativamente diferente de uma matriz identidade.

Portanto, neste caso, tanto o MO quanto o Teste de Esfericidade de Bartlett indicaram haver condições para a realização da análise fatorial.
Por isso, passou-se à segunda etapa.

#### Identificação do número de fatores a serem retidos na análise

Para essa verificação, três métodos são comumente utilizados:

1.  A regra do eigenvalue maior que 1
2.  O scree-plot (ou, gráfico de sedimentação)
3.  A análise paralela

O scree-plot ajuda a resolver os dois primeiros casos.

```{r}
big_five %>% select(9:58) %>% 
  scree(pc = FALSE) # extrair fatores, não extrair componentes
```

Pela inspeção do scree-plot, observa-se a curva formada pelos pontos e seleciona-se os que apresentam eigenvalues mais elevados, após o ponto de inflexão da curva.
Por esse critério, poder-se ia selecionar 6 pontos (fatores)(regra 2).
No entanto, há apenas 5 deles com eigenvalues superiores a 1 (regra 1).
Portanto, selecionam-se cinco fatores, que coincide com o número de fatores esperado pela teoria (big five).

A análise paralela é um procedimento que compara eigenvalues obtidos com os dados experimentais e com matrizes de dados aleatórios.
Seleciona-se o número de fatores que apresentaram eigenvalues experimentias superiores aos aleatórios.

```{r}
big_five %>% select(9:58) %>% fa.parallel()
```

A análise paralela resultou na indicação de 10 fatores.
Veja tabela abaixo.

```{r}
data.frame(as.data.frame(parallel_bigfive$fa.values),
           as.data.frame(parallel_bigfive$fa.sim)) %>% pander()
```

Note que os 10 primeiros valores experimentais (col_1) são superiores aos respectivos valores simulados (col_2).
No entanto, somente os cinco primeiros valores experimentais são superiores a 1.
Portanto, depreende-se do conjunto dos três critérios que **devem ser retidos cinco fatores**.

#### Extração dos fatores

Uma curiosidade... em uma análise fatorial, é esperado que os itens de um mesmo fator se correlacionem mais entre si do que com itens de outros fatores.
Isso pode ser observado na plotagem das correlações entre os itens.

```{r}
# matriz de correlações usando o corrplot
corrplot::corrplot(corr.test(big_five[,9:58])$r, order = "original", type = "lower",
                   title = "Correlação entre os itens - big_five")
```

Essa correlação entre os itens não precisa ser realizada antes da análise fatorial.
Fizemos aqui apenas a título de curiosidade.
Em seguida, passamos à extração dos fatores propriamente dita.

```{r}
fa_big_five <- big_five %>% select(9:58) %>% fa(nfactors = 5, 
                                                rotate = "geominQ", 
                                                fm = "uls")

# para visualizar as cargas fatoriais
summary(fa_big_five)
```

## Fidedignidade

Após a identificação da (validade com base na) estrutura interna do instrumento, em psicometria (construção de instrumentos), costuma-se verificar a fidedignidade (precisão) dos fatores.
Os principais métodos reportados são o coeficiente alfa de Cronbach e o ômega de McDonald.

Ambos podem ser encontrados na função `omega()` do pacote `psych`.

```{r}
# os itens negativos já foram invertidos anteriormente.

rely_E <- big_five %>% select( 9:18) %>% omega(poly=TRUE, digits=2, plot=FALSE)
rely_N <- big_five %>% select(19:28) %>% omega(poly=TRUE, digits=2, plot=FALSE)
rely_A <- big_five %>% select(29:38) %>% omega(poly=TRUE, digits=2, plot=FALSE)
rely_C <- big_five %>% select(39:48) %>% omega(poly=TRUE, digits=2, plot=FALSE)
rely_O <- big_five %>% select(49:58) %>% omega(poly=TRUE, digits=2, plot=FALSE)

# apresentação numa tabela

data.frame(Fatores = c('Extroversão', 
                       'Neuroticismo', 
                       'Amabilidade', 
                       'Conscienciosidade', 
                       'Abertura'),
           Alfa = c(rely_E$alpha, 
                    rely_N$alpha, 
                    rely_A$alpha, 
                    rely_C$alpha, 
                    rely_O$alpha),
           Omega = c(rely_E$omega.tot, 
                     rely_N$omega.tot, 
                     rely_A$omega.tot, 
                     rely_C$omega.tot, 
                     rely_O$omega.tot)) %>% pander()
```

## Exercícios sobre qui-quadrado

Dica: para que as categorias de ansiedade e depressão sejam mostradas em ordem crescente (mínima, leve, moderada, grave), é necessário informar o R sobre isso por meio do argumento `levels` da função `factor`.

1.  Calcular o qui-quadrado para verificar as associações entre sexo e ansiedade (bai_class). Represente os dados em uma tabela.

```{r}
glimpse(dataset)

# padronizar a ordem dos níveis: minima, leve, moderada, grave.
dataset$bai_class <- factor(dataset$bai_class,
                            levels = c("minima",
                                       "leve",
                                       "moderada",
                                       "grave"))
# Cálculo do qui-quadrado

chisq.test(                               # função para cálculo do qui-quadrado
  table(dataset$bai_class, dataset$sex))  # tabulação dos dados

# Representação dos dados em tabela
dataset %>% 
  tabyl(bai_class,sex,show_na = FALSE) %>%   # função de tabulação do janitor
  adorn_totals(c("row","col")) %>%           # adiciona o N
  adorn_percentages("col") %>%               # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(                
    rounding = "half up",                    # arredondar do cinco pra cima
    digits = 0) %>%                          # número de casas decimais
  adorn_ns() %>%                             # mostra N e % juntas
  pander()                                   # melhora a visualização dos dados.
```

O teste de qui-quadrado (X^2^~(gl=3, N=1945)~ = 44.767, p \< 0,001) foi estatisticamente significativo, indicando haver diferenças na distribuição da classificação de ansiedade por sexo.
A tabela XX mostra que as mulheres apresentam menor porcentagem de casos de ansiedade **mínima**, maior porcentagem de casos de ansiedade **leve** e **moderada** e praticamente a mesma porcentagem de casos **graves**.

2.  Calcular o qui-quadrado para verificar as associações entre sexo e depressão (bdi_class). Represente os dados em uma tabela.

```{r}
dataset$bdi_class <- factor(dataset$bdi_class,
                            levels = c("minima",
                                       "leve",
                                       "moderada",
                                       "grave"))

chisq.test(table(dataset$bdi_class, dataset$sex))

# Representação dos dados em tabela
dataset %>% 
  tabyl(bdi_class,sex,show_na = FALSE) %>%   # função de tabulação do janitor
  adorn_totals(c("row","col")) %>%           # adiciona o N
  adorn_percentages("col") %>%               # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(                
    rounding = "half up",                    # arredondar do cinco pra cima
    digits = 0) %>%                          # número de casas decimais
  adorn_ns() %>%                             # mostra N e % juntas
  pander()                                   # melhora a visualização dos dados.
```

O teste de qui-quadrado (X^2^~(gl=3, N=1942)~ = 9.022, p = 0,029) foi estatisticamente significativo, indicando haver diferenças na distribuição da classificação de depressão por sexo.
A tabela XX mostra que as mulheres apresentam menor porcentagem de casos de mínima **mínima**, maior porcentagem de casos de depressão **leve** e **moderada** e a mesma porcentagem de casos **graves**.

3.  Calcular o qui-quadrado para verificar as associações entre país e ansiedade (bai_class). Represente os dados em um gráfico.

```{r}
# Cálculo do qui-quadrado
chisq.test(                               # função para cálculo do qui-quadrado
  table(dataset$bai_class, dataset$country))  # tabulação dos dados

# Representação dos dados em tabela
dataset %>% 
  tabyl(bai_class,country,show_na = FALSE) %>%   # função de tabulação do janitor
  adorn_totals(c("row","col")) %>%           # adiciona o N
  adorn_percentages("col") %>%               # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(                
    rounding = "half up",                    # arredondar do cinco pra cima
    digits = 0) %>%                          # número de casas decimais
  adorn_ns() %>%                             # mostra N e % juntas
  pander()                                   # melhora a visualização dos dados.
```

4.  Calcular o qui-quadrado para verificar as associações entre país e depressão (bdi_class). Represente os dados em um gráfico.

```{r}
chisq.test(table(dataset$bdi_class, dataset$country))

# Representação dos dados em tabela
dataset %>% 
  tabyl(bdi_class,country,show_na = FALSE) %>%   # função de tabulação do janitor
  adorn_totals(c("row","col")) %>%           # adiciona o N
  adorn_percentages("col") %>%               # adiciona porcentagens (One of "row", "col", or "all".)
  adorn_pct_formatting(                
    rounding = "half up",                    # arredondar do cinco pra cima
    digits = 0) %>%                          # número de casas decimais
  adorn_ns() %>%                             # mostra N e % juntas
  pander()                                   # melhora a visualização dos dados.
```

## Exercícios sobre correlação

Baixe o banco de dados [rwas_us.xlsx](https://docs.google.com/spreadsheets/d/1ja_BnmHO4iXTYgIV__b8ZXvqIJi8506IERb7W6kp2Js/edit?usp=sharing), que foi empregado em um estudo sobre autoritarismo conservador, e cole-o no mesmo diretório em que você está salvando seus arquivos para este estudo.
Para mais informações sobre as variáveis desse banco de dados, baixe também [este arquivo](https://docs.google.com/document/d/1oOXxYNLe7nd8kkK7QyOKu_2KiDqfO-wuyDuKbB17iz0/edit?usp=sharing).
Importe esse banco de dados para o R.
Note que ele está no formato `.xlsx`, um arquivo de excel.
Portanto, para importá-lo para dentro do R, use a função `readxl::read_xlsx("rwas_us.xlsx")`.

Em seguida, use esse banco de dados para realizar os exercício abaixo.

1.  Calcule as correlações (r) e os índices de significância (p) entre os cinco grandes fatores de personalidade (extr, neur, amab, cons e aber).

```{r}

rwas_us %>% select(extr,neur,amab,cons,aber) %>% corr.test(method = "pearson")
names(rwas)
# rwas_br <- rwas %>% filter(IP_country == "BR")
# glimpse(rwas_br)
```

2.  Calcule as correlações (r) e os índices de significância (p) dos cinco grandes fatores de personalidade (extr, neur, amab, cons e aber) com raciocínio verbal (rv) e autoritarismo (auth), mas expresse os resultados com os traços de personalidade nas linhas e o rv e o auth nas colunas.

```{r}
names(rwas_us)
corr.test(rwas_us[,91:95],rwas_us[,c(96,97)])
```

3.  Faça um gráfico de pontos para cada par de correlações entre cinco grandes fatores.

```{r}
pairs.panels(rwas_us[,c('extr','neur','amab','cons','aber')])

ggplot(rwas_us, aes(x=extr,y=neur)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Extroversão e Neuroticismo", 
       x = "Extroversão", 
       y = "Neuroticismo") +
  theme_classic()
```

4.  Faça um gráfico de calor (corrplot) para as correlações entre os cinco grandes fatores.

```{r}
# Em dois passos

## Cálculo das correlações e p-values
matriz_bigfive <- corr.test(rwas_us[,91:95])

## Utilização da matriz de correlações para fazer o gráfico
corrplot::corrplot(matriz_bigfive$r, 
                   order = "original", 
                   type = "lower",
                   title = "Correlação entre os fatores bif five")

### Gráfico em apenas uma etapa
corrplot::corrplot(corr.test(rwas_us[,91:95])$r, 
                   order = "original", 
                   type = "lower",
                   title = "Correlação entre os fatores bif five")
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# saveRDS(rwas_us,"rwas_us.rds")
rwas_us <- readRDS("rwas_us.rds")

# 1. Calcule as correlações (r) e os índices de significância (p) entre os cinco grandes fatores de personalidade (extr, neur, amab, cons e aber).
round(corr.test(rwas_us[,91:95], method = "pearson")$r,digits = 2)
round(corr.test(rwas_us[,91:95], method = "pearson")$p,digits = 2)

# 2. Calcule as correlações (r) e os índices de significância (p) dos cinco grandes fatores de personalidade (extr, neur, amab, cons e aber) com raciocínio verbal (rv) e autoritarismo (auth), mas expresse os resultados com os traços de personalidade nas linhas e o rv e o auth nas colunas.
corr.test(rwas_us[,91:96],rwas_us[,c(96,97)])$r
corr.test(rwas_us[,91:95],rwas_us[,c(96,97)])$p

# 3. Faça um gráfico de pontos para cada par de correlações entre cinco grandes fatores.

ggplot(rwas_us, aes(x=extr,y=neur)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Extroversão e Neuroticismo", 
       x = "Extroversão", 
       y = "Neuroticismo") +
  theme_classic()

# ggplot(rwas_us, aes(x=extr,y=amab)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Extroversão e Amabilidade", 
#        x = "Extroversão", 
#        y = "Amabilidade") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=extr,y=cons)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Extroversão e Conscienciosidade", 
#        x = "Extroversão", 
#        y = "Conscienciosidade") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=extr,y=aber)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Extroversão e Abertura", 
#        x = "Extroversão", 
#        y = "Abertura") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=neur,y=amab)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Neuroticismo e Amabilidade", 
#        x = "Neuroticismo", 
#        y = "Amabilidade") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=neur,y=cons)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Neuroticismo e Conscienciosidade", 
#        x = "Neuroticismo", 
#        y = "Conscienciosidade") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=neur,y=aber)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Neuroticismo e Abertura", 
#        x = "Neuroticismo", 
#        y = "Abertura") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=amab,y=cons)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Amabilidade e Conscienciosidade", 
#        x = "Amabilidade", 
#        y = "Conscienciosidade") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=amab,y=aber)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Amabilidade e Abertura", 
#        x = "Amabilidade", 
#        y = "Abertura") +
#   theme_classic()
# 
# ggplot(rwas_us, aes(x=cons,y=aber)) +
#   geom_jitter() +
#   geom_smooth(method = "lm") +
#   labs(title ="Correlação entre Conscienciosidade e Abertura", 
#        x = "Conscienciosidade", 
#        y = "Abertura") +
#   theme_classic()

# 4. Faça um gráfico de calor (heat map) para as correlações entre os cinco grandes fatores.
round(corr.test(rwas_us[,91:95], method = "pearson")$r,digits = 2) %>% 
corrplot::corrplot(method = "shade",
                   type = "lower",
                   order = "hclust",
                   addCoef.col = TRUE)
```

## Exercícios sobre regressão linear múltipla

Utilizando o arquivo rwas_us, que já empregamos no exercício anterior, realizar uma análise de regressão para verificar se os traços de personalidade (extr, neur, amab, cons e aber) e o raciocínio verbal (rv) predizem autoritarismo (auth).
Interprete os resultados.

```{r include=FALSE}
names(rwas_us)
mod_rwas_us <- lm(auth ~ extr+neur+amab+cons+aber+rv,
                  data=rwas_us,
                  na.action = na.omit)
summary(mod_rwas_us)
```

## Exercício com análise fatorial exploratória

Realizar uma análise fatorial exploratória com os itens do BDI e do BAI que integram o dataframe `dataset`.
Faça uma análise de sedimentação (scree-plot) para determinar o número de fatores.
Rode a análise fatorial exploratória com o número de fatores sugerido pelo scree-plot e verifique a distribuição dos itens.
Pela teoria, seria esperada a formação de dois fatores, um com os itens de depressão e outro com os itens de ansiedade.
Considere que as cargas superiores a 0,3 para que o item integre um fator.
Observe a correlação entre os fatores.

```{r include=FALSE}

names(dataset) %>% as.data.frame()
# ANÁLISE FATORIAL

## Condições para realização da análise fatorial
dataset %>% select(46:87) %>% KMO()
dataset %>% select(46:87) %>% bartlett.test()

## Determinação do número de fatores a serem retidos

dataset %>% dplyr::select(46:87) %>% scree(pc = FALSE)


## AFE
fa_ansdep <- dataset %>% dplyr::select(46:87) %>% fa(nfactors = 2, 
                                           cor = "cor",
                                           fm = "wls",
                                           rotate = "geominQ")

```

# Estatísticas para análise de efeitos de grupos

Em muitas pesquisas, o interesse recai sobre os efeitos de grupo.
Nesses casos, investiga-se se o fato das pessoas perteceram a um grupo produz efeito em alguma variável psicológica.
Por exemplo, qual é o efeito de sexo (masculino ou feminino) na variável inteligência?
Qual é o efeito de um programa de desenvolvimento da inteligência emocional (grupos controle e experimental) sobre a qualidade de vida?
Qual o efeito do país de origem (A, B, C) no desempenho escolar?
As análises estatísticas que normalmente são usadas nesses estudos são as seguintes:

-   Teste t

-   Análise de variância de uma via (ANOVA)

-   Análise de varância univariada

-   Análise de variância multivariada (MANOVA)

-   Anova Fatorial Análise de Covariância (ANCOVA)

-   Análise Multivariada de Covariância (MANCOVA)

-   Análise de variância por medidas repetidas

# Teste t

Quando queremos comparar uma variável do nosso banco de dados com os dados constantes na literatura (por exemplo, as pontuações em depressão da nossa amostra com a média da população), usamos o **teste t para uma amostra**.
Como exemplo, vamos usar o banco de dados `big_five_BR`, para investigar se as pontuações em neuroticismo dos brasileiros é significativamente diferentes da média encontrada nos diversos países em que a escala foi aplicada.
Para isso, começamos investigando se a distribuição das pontuações é ao menos próxima da distribuição normal.

### Média da amostra sem participantes brasileiros (referência)

```{r}
# seleção de um subset do datarame big_five somente com os participantes NÃO-BRASILEIROS na variável neur 
média_neur <- big_five %>% 
  filter(!país == "BR") %>% 
  select("neur")

# cálculo da média dos participantes NÃO-BRASILEIROS em neur
# Esse resultado será utilizado como referência no t-teste
round(mean(média_neur$neur, na.rm = TRUE),digits = 2)
```

### Seleção de participantes brasileiros

```{r}
big_five_BR <- big_five %>% 
  filter(país == "BR")
```

# Teste-t para uma amostra

```{r}

t.test(                # t.test é o comando do stats
  big_five_BR$neur,    # localização da variável neur em brasileiros
  mu = 3.09)           # valor de referência, calculado anteriormente
```

Encontrou-se uma diferença estatisticamente significativa entre as médias (t = 4,0, gl = 174, p-valor = 9,331e-05), em que os participantes brasileiros apresentaram um valor mais elevado (neur_BR = 3,335) que o de participantes de outros países.
(neur_outros = 3,09, como calculado anteriormente).

### Representação em Tabela

```{r}
big_five %>% 
  drop_na(neur, país) %>% 
  mutate(país_dic = ifelse(país == "BR", "BR", "MUNDO")) %>% 
  group_by(país_dic) %>% 
  summarise(média = mean(neur),
            "Desvio padrão" = sd(neur)) %>% pander()
```

### Representação Gráfica

```{r}
## install.packages("pacman")
# OBS: a função p_load do pacote pacman verifica se um pacote está instalado e instala se for necessário.

pacman::p_load(ggpubr) # ggpubr é um pacote que adiciona algumas funções ao ggplot
                       # com isso fica possível usar a função mean_ci e desvio padrão
                       # para calcular intervalo de confiança.

# criação de uma variável categórica (nominal) para diferenciar BR de outros
big_five %>% mutate(País = ifelse(país == "BR","BR","OU")) %>% drop_na() %>%
# 1ª camada: gráfico de pontos  
ggplot(aes(x = País, y = neur)) +
  geom_point(stat = "summary", fun = "mean", na.rm = TRUE) +
# 2ª camada: barras com desvio padrão  
  geom_errorbar(stat = "summary", fun.data = "mean_sd", width = 0.3, na.rm = TRUE) + 
# Redimensionamento do eixo y
  coord_cartesian(ylim = c(1,5)) +
# Título e rótulos dos eixos
  labs(title = "Média de Neuroticismo: Brasil x Mundo",
       x = "País",
       y = "Neuroticismo")
```

# Teste-t para amostras independentes

Essa análise estatística se aplica à comparação das médias de dois grupos em que os participantes estão em um grupo OU em outro, não sendo possível estar nos dois grupos ao mesmo tempo.
Por isso a denominação de **amostras independentes**.
Para isso, vamos usar o dataframe big_five_BR e analisar o efeito de gênero (sexo, na verdade, pois só consideraremos as categorias **masculino** e **feminino**) nos cinco grandes fatores de personalidade.

### Preparação do banco de dados e carregamento dos pacotes

Para a realização dessa análise vamos usar o pacote `car`, que será empregado apenas em poucas análises, então não precisamos carregar o pacote (para não sobrecarregar o sistema), mas apenas chamar a função desejada do pacote.

Então, temos que preparar a variável gênero do dataframe big_five_BR, que contem três categorias (masculino, feminino e outro).
Como o teste-t só funciona para duas categorias e a categoria gênero apresenta apenas duas observações "outro", vamos selecionar somente os participantes que declararam sexo masculino ou feminino e salvar esse novo dataframe com o nome de *big_five_BR_nona*.

```{r}
# primeiro passo: transformar a categoria "outros" em NA

big_five_BR %>% select(gênero) %>% distinct()

big_five_BR_nona <- big_five_BR %>% filter(gênero %in% c('Masculino', 'Feminino'))

big_five_BR_nona %>% select(gênero) %>% distinct()
```

### Verificação da homogeneidade das variâncias

Um primeiro passo para a realização do t-teste para amostras independentes é a verificação da homogeneidade das variâncias, por meio do teste de Levene.
Para isso, vamos usar a função `leveneTest()` do pacote `car`.

```{r}
# install.packages("car")

# Teste de Levene usando o pacote car

car::leveneTest(extr ~ gênero, big_five_BR_nona, center=mean)
car::leveneTest(neur ~ gênero, big_five_BR_nona, center=mean)
car::leveneTest(amab ~ gênero, big_five_BR_nona, center=mean)
car::leveneTest(cons ~ gênero, big_five_BR_nona, center=mean)
car::leveneTest(aber ~ gênero, big_five_BR_nona, center=mean)

## OBS: Por default, o teste realizado pelo pacote car tem como base a mediana, que é mais robusto, mas, para ficar igual ao SPSS, mudamos para a média, por isso o argumento center=mean.
```

Observou-se que todos os p-valores foram superiores a 0,05, indicando não haver diferenças significativas entre as variâncias, que, portanto, podem ser assumidas como homogêneas.
Sendo assim, parte-se para a realização dos *testes t* propriamente ditos.

```{r}
t_extr <- t.test(extr ~ gênero, big_five_BR_nona, var.equal = TRUE)
t_neur <- t.test(neur ~ gênero, big_five_BR_nona, var.equal = TRUE)
t_amab <- t.test(amab ~ gênero, big_five_BR_nona, var.equal = TRUE)
t_cons <- t.test(cons ~ gênero, big_five_BR_nona, var.equal = TRUE)
t_aber <- t.test(aber ~ gênero, big_five_BR_nona, var.equal = TRUE)
```

Observa-se que houve diferença estatisticamente significativa apenas no traço de amabilidade, em que a média das mulheres (`r big_five_BR_nona %>% filter(gênero == "Feminino") %>% select(amab) %>% summarise(média = round(mean(amab),digits = 1))`) foi superior à dos homens((`r big_five_BR_nona %>% filter(gênero == "Masculino") %>% select(amab) %>% summarise(média = round(mean(amab),digits = 1))`)).

### Cálculo do Tamanho do Efeito (d de Cohen)

```{r}
# install.packages("effsize")

effsize::cohen.d(amab ~ gênero, data = big_five_BR_nona)

data.frame("d de Cohen" = c("< 0,2",
                            "> 0,2 até 0,5",
                            "> 0,5 até 0,8",
                            "> 0.8"),
           "Interpretação" = c("irrelevante",
                               "pequeno",
                               "moderado",
                               "grande")) %>% pander()

```

Obteve-se um d de Cohen igual a -0.3213846, considerado pequeno conforme a tabela de referência.
Ou seja, o teste t foi estatisticamente significativo, indicando que **é pouco provável** que a diferença entre homens e mulheres tenha sido obtida ao acaso.
No entanto, a diferença (efeito) causada por gênero no traço de amabilidade é pequeno.

### Apresentação dos resultados em uma tabela

```{r}
data.frame(Variável = c("Extroversão","Neuroticismo","Amabilidade",
                        "Conscienciosidade","Abertura"),
           t = c(round(t_extr$statistic,digits = 3),
                 round(t_neur$statistic,digits = 3),
                 round(t_amab$statistic,digits = 3),
                 round(t_cons$statistic,digits = 3),
                 round(t_aber$statistic,digits = 3)),
           gl = c(t_extr$parameter,
                  t_neur$parameter,
                  t_amab$parameter,
                  t_cons$parameter,
                  t_aber$parameter),
           p = c(round(t_extr$p.value,digits = 3),
                 round(t_neur$p.value,digits = 3),
                 round(t_amab$p.value,digits = 3),
                 round(t_cons$p.value,digits = 3),
                 round(t_aber$p.value,digits = 3)),
           M = c(round(t_extr$estimate[1],digits=2),
                 round(t_neur$estimate[1],digits=2),
                 round(t_amab$estimate[1],digits=2),
                 round(t_cons$estimate[1],digits=2),
                 round(t_aber$estimate[1],digits=2)),
           "F"=c(round(t_extr$estimate[2],digits=2),
                 round(t_neur$estimate[2],digits=2),
                 round(t_amab$estimate[2],digits=2),
                 round(t_cons$estimate[2],digits=2),
                 round(t_aber$estimate[2],digits=2))) %>% pander()
```

Juntamente com esse resultado, é necessário apresentar as estatísticas descritivas.
Então, a tabela poderia ficar assim.

```{r}
## Usando a função tableby do pacote arsenal

tableby(gênero ~ extr + neur + amab + cons + aber,
        test = FALSE,
        data = big_five_BR_nona) %>%
  summary(text = TRUE)
```

### Representação gráfica (VER DEPOIS)

```{r}
# usando o graphics (base do R)
boxplot(amab ~ gênero, big_five_BR, ylab = "Amabilidade", xlab = "Sexo")

# MESMO PROBLEMA ANTERIOR.
```

# Teste-t para amostras pareadas

Muitas vezes, os pesquisadores estão interessados em comparar o mesmo grupo de pessoas em duas situações diferentes, como por exemplo, antes e após alguma intervenção (pré e pós-teste).
Como o grupo de pessoas é o mesmo, diz-se que o teste-t é para **amostras pareadas**.

Para realizar essa análise, vamos utilizar um **banco de dados fictício** que contém duas supostas medidas de habilidades em leitura, uma realizada antes de um programa de intervenção para estimulação da leitura (pre_teste), e uma realizada após o programa (pos_teste).

```{r}
# Criação de um dataframe para análise de dados pareados
df <- data.frame(id = paste("s",1:30,sep=""),
                 pre_teste = rnorm(30, mean = 5.14, sd = 1.23),
                 pos_teste = rnorm(30, mean = 6.78, sd = 0.93))

saveRDS(df, "df.rds")
```

### Teste-t para amostras pareadas

```{r}
# Teste t
t_par <- t.test(df$pos_teste,df$pre_teste,paired = TRUE)


# Cálculo do Tamanho do efeito
effsize::cohen.d(df$pos_teste,df$pre_teste,paired = TRUE)

```

A diferença de médias entre o pré e o pós teste foi estatisticamente significativa (t = 5,4704, gl = 29, p-valor = 6.867e-06), com a média do pós-teste (6,864) superior à média do pré-teste (4,916).
O coeficiente d de Cohen foi de 1,59, indicando que o tamanho do efeito da intervenção foi grande.

OBS: Lembrar que os dados são fictícios.

### Apresentação dos resultados em uma tabela

```{r}
# usando a função summary

summary(df$pre_teste)
summary(df$pos_teste)

# criando um dataframe com as informações 
data.frame(Variáves = c("Pré-teste",
                        "Pós-teste"),
           Média = c(round(mean(df$pre_teste,na.rm=TRUE),digits=2),
                     round(mean(df$pos_teste,na.rm=TRUE),digits=2)),
           "Desv. Padrão" = c(round(sd(df$pre_teste,na.rm=TRUE),digits=2),
                              round(sd(df$pos_teste,na.rm=TRUE),digits=2))) %>% pander()
```

### Representação gráfica

```{r}
par(mfrow=c(1,2)) # função para apresentar gráficos em paralelo
                  # diz que em uma linha vão entrar dois gráficos (1,2)

boxplot(df$pre_teste, ylab="Leitura - Pré-teste", xlab="Pré-Teste")
boxplot(df$pos_teste, ylab="Leitura - Pós-teste", xlab="Pós-Teste")

par(mfrow=c(1,1)) # voltar para um gráfico por linha.
```

# Análise de Variância

O teste-t apresenta uma limitação importante, que é a de só conseguir comparar **duas** categorias de uma variável.
Para superar essa limitação e podermos comparar mais de duas categorias de uma variável é preciso utilizar uma Análise de Variância (ANOVA).

# ANOVA de uma via

Para realizar essa análise vamos usar o dataframe `rwas` para verificar se há efeito do nível de escolaridade (fundamental, médio, superior, pós-graduação) sobre a medida de *autoritarismo de direita* realizada pelo Right Wing Authoritarianism Scale.
Para isso, é necessário [importar o banco de dados](https://github.com/jmhbueno/R_Stat/blob/9577839ebbc25524d57ce34dddc93a0b54342317/rwas.rds) e salvar na pasta que você está utilizando para este curso.
Em seguida, use o código abaixo para importar o arquivo e salvá-lo como um objeto (dataframe) do R.

```{r}
rwas <- readRDS("rwas.rds")

```

### ANOVA de uma via

```{r}
# Criação do modelo usando a função aov do pacote stats (Base do R)
anova_auth <- aov(auth ~ education, rwas)

# visualização dos resultados
summary(anova_auth)
```

Nesse caso, há quatro categorias dentro da variável education:

`r distinct(rwas,education) %>% pander()`

O fato de a ANOVA ter sido estatisticamente significativa nos diz que há diferenças importantes nessas quatro categorias, mas não conhecemos par a par, se há diferenças ou não.
Para isso, é preciso empregar os **Testes Post-Hoc**, que fazem comparações múltiplas, dois a dois.
Para realizar esses testes, precisamos instalar o pacote `DescTools`, para poder utilizar a função `PostHocTest()`.

```{r}
# Testes de post-hoc
# post-hocs permitidos: "hsd" (Tukey's HSD), "bonferroni", "lsd", "scheffe", "duncan"

#install.packages("DescTools")
# library(DescTools)
DescTools::PostHocTest(anova_auth, method = "hsd", conf.level = 0.95)

```

Observa-se que há diferenças estatisticamente significativas entre todos os pares.
Isso ocorre, neste caso, porque o número de participantes da pesquisa é muito alto (N=`r nrow(rwas)`).
Normalmente, para uma ANOVA de uma via, recomenda-se o F de Cohen.

```{r}
# Tamanho do efeito

# install.packages("effectsize")

effectsize::cohens_f(
  anova_auth,
  partial = TRUE,
  squared = FALSE,
  model2 = NULL,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE)

# referência (Steiger e Fouladi, 1997/2016)
data.frame("f de Cohen" = c("< 0,10",
                            "> 0,10 até 0,25",
                            "> 0,25 até 0,40",
                            "> 0.40"),
           "Interpretação" = c("irrelevante",
                               "pequeno",
                               "médio",
                               "grande")) %>% pander()

# effectsize::eta_squared(
#   anova_auth,
#   partial = TRUE,
#   generalized = FALSE,
#   ci = 0.95,
#   alternative = "greater",
#   verbose = TRUE)
# 
# effectsize::omega_squared(
#   anova_auth,
#   partial = TRUE,
#   ci = 0.95,
#   alternative = "greater",
#   verbose = TRUE)
# 
# effectsize::epsilon_squared(
#   anova_auth,
#   partial = TRUE,
#   ci = 0.95,
#   alternative = "greater",
#   verbose = TRUE)
# 
# 
# effectsize::cohens_f_squared(
#   anova_auth,
#   partial = TRUE,
#   squared = TRUE,
#   model2 = NULL,
#   ci = 0.95,
#   alternative = "greater",
#   verbose = TRUE)

```

### Apresentação dos dados em tabela

```{r}
# usando a função tableby() do pacote arsenal
# muito simples, mas a tabela fica muito larga e não cabe na página
one_way_anova_tab <- arsenal::tableby(education ~ auth, 
                                      digits = 1, 
                                      test = FALSE, 
                                      rwas)

summary(one_way_anova_tab,text=TRUE)

# criando uma dataframe

data.frame(Escolaridade = c("Less than high school",
                            "High school",
                            "University degree",
                            "Graduate degree"),
           Média = 
             c(round(mean(rwas[rwas$education == "Less than high school",]$auth, na.rm = TRUE),digits=1),
               round(mean(rwas[rwas$education == "High school",]$auth, na.rm = TRUE),digits=1),
               round(mean(rwas[rwas$education == "University degree",]$auth, na.rm = TRUE),digits=1),
               round(mean(rwas[rwas$education == "Graduate degree",]$auth, na.rm = TRUE),digits=1)),
           DesvPad = 
             c(round(sd(rwas[rwas$education == "Less than high school",]$auth, na.rm = TRUE),digits=1),
               round(sd(rwas[rwas$education == "High school",]$auth, na.rm = TRUE),digits=1),
               round(sd(rwas[rwas$education == "University degree",]$auth, na.rm = TRUE),digits=1),
               round(sd(rwas[rwas$education == "Graduate degree",]$auth, na.rm = TRUE),digits=1))) %>% 
  pander()
```

### Representação gráfica

```{r}
ggplot(rwas, aes(x = education, y = auth)) + 
  geom_boxplot(color = "black", fill = "#74c69d") +
  labs(title = "Autoritarismo por nível de escolaridade",
       x = "Escolaridade",
       y = "Autoritarismo") + 
  coord_flip()
```

Relato de resultados, considerando os resultados de uma forma geral: *Houve efeito significativo do nível de escolaridade (education) sobre o autoritarismo de direita (F~(gl=3, N=9881)~ = 102, p-valor = \<2e-16). Uma análise post-hoc de comparações multiplas, empregando o Método HSD de Tukey, mostrou que todas as comparações foram estatisticamente significativas, o que provavelmente ocorreu devido ao tamanho da amostra. O tamanho do efeito, no entanto, calculado pela estatística F de Cohen, foi de 0,18, considerado pequeno. As estatísticas descritivas mostram que conforme o nível de escolaridade aumenta, o autoritarismo de direita diminui.*

# ANOVA de medidas repetidas

A ANOVA de uma via permite comparar 3 ou mais grupos (por exemplo, níveis de escolaridade) quanto a uma variável (por exemplo, autoritarismo), como vimos no exemplo anterior.
No entanto, essa análise se aplica a somente uma variável dependente e a grupos independentes.
Se quisermos realizar uma comparação de grupos pareados ao longo de duas ou mais medidas, teremos que usar uma ANOVA de medidas repetidas.
Para isso precisaremos instalar o pacote `ez`, que facilita a realização dessa análise.

### Instalação de pacotes

```{r}
# install.packages("ez")
library(ez)
```

### Geração de um banco de dados

Para realizar essa análise, vamos gerar um **banco de dados fictício** em que a variável *id* identifica os sujeitos (N = 100), e as variáveis de *v1* a *v5* representam as medidas repetidas.
Nesse caso, vamos **SUPOR** a seguinte situação como problema de pesquisa.
Um novo programa para a prática de mindfulness **(FICTÍCIO)** teria sido aplicado a um grupo de praticantes e a pergunta é se esse programa desenvolve habilidades relacionadas ao mindfulness.
Portanto, as cinco medidas encontradas no dataframe `df_aov_mr` (v1 a v5) estão fazendo o papel de uma avaliação de habilidades para a prática de mindfulness.

```{r}
df_aov_mr <- data.frame(id = paste("s",1:100,sep = ""),
                        v1 = round(rnorm(n=100, mean = -1.2, sd = 0.54),digits = 3),
                        v2 = round(rnorm(n=100, mean = -0.7, sd = 0.52),digits = 3),
                        v3 = round(rnorm(n=100, mean = -0.1, sd = 0.57),digits = 3),
                        v4 = round(rnorm(n=100, mean =  0.4, sd = 0.55),digits = 3),
                        v5 = round(rnorm(n=100, mean =  0.5, sd = 0.54),digits = 3))
                        
glimpse(df_aov_mr)
```

### Transformação do banco de dados

Para a realização da análise de variância por medidas repetidas é necessário transformar o banco de dados para que as medidas repetidas fiquem em uma linha diferente.
Geralmente, nossos banco de dados estão no formato **amplo** (wide), mas a análise de medidas repetidas tem que ser realizada com um banco de dados no formato **longo** (long).

```{r}
# Usando a função pivot_longer() do tidyverse

df_aov1 <- 
df_aov_mr %>% pivot_longer(cols = 2:6,            # variáveis a serem unidas em uma só.  
                           names_to = "tempo",    # nome dessa nova variável 
                           values_to = "valores") # valores correspondentes à nova variável 

# transformar as variáveis id e tempo em fatores
df_aov1$id <- factor(df_aov1$id)
df_aov1$tempo <- factor(df_aov1$tempo)

glimpse(df_aov1)
```

### ANOVA de medidas repetidas

```{r}
mod_df_aov1 <- ez::ezANOVA(data = df_aov1,    # banco de dados no formato longo
                    dv = valores,             # variável dependente
                    wid = id,                 # variável que identifica os sujeitos
                    within = tempo,           # variável intra-sujeitos
                    detailed = TRUE,          # saída mais detalhada
                    type = 3)                 # tipo de soma dos quadrados, default 2

# o efeito de variable foi significativo (6.484458e-85)
# O Mauchly's Test de esfericidade. Caso os dados não sejam esféricos, tem que interpretar os dados Sphericity Corrections, que corrigem os graus de liberdade.
# Geralmente, usamos a correçaõ de Greenhouse-Geisser (GGe), mais conservadora.
# Mas o pacote tb informa o valor de Huynh-Feldt (HFe)
# Como esses índices foram significativos, concluímos que há diferenças entre as cinco medidas.
```

Comparações múltiplas para a verificação de diferenças para a par.
Emprega-se uma série de testes-t pareados com p-valor ajustado pelo método de Bonferroni.

```{r}
# Testes post-hoc
pairwise.t.test(df_aov1$valores, df_aov1$tempo, paired = TRUE,
                p.adjust.method = "bonferroni")

```

Todas as diferenças entre os pares de medidas foram estatisticamente significativas, exceto entre v4 e v5.
### Visualização dos dados em tabela

```{r}
table_AOV_medrep <- 
data.frame(variáveis = c('v1','v2','v3','v4','v5'),
           médias = c(round(mean(df_aov_mr$v1),digits = 2),
                      round(mean(df_aov_mr$v2),digits = 2),
                      round(mean(df_aov_mr$v3),digits = 2),
                      round(mean(df_aov_mr$v4),digits = 2),
                      round(mean(df_aov_mr$v5),digits = 2)),
           desvpad = c(round(sd(df_aov_mr$v1),digits = 2),
                       round(sd(df_aov_mr$v2),digits = 2),
                       round(sd(df_aov_mr$v3),digits = 2),
                       round(sd(df_aov_mr$v4),digits = 2),
                       round(sd(df_aov_mr$v5),digits = 2)))

table_AOV_medrep %>% pander()
# rstatix::get_summary_stats(df_aov_mr,v1, type = "mean_sd")
```

Nota-se que as médias vão aumentando prograssivamente de v1 a v5.
Porém, como visto anteriormente, a diferença entre v4 e v5 não foi estatisticamente significativa.

### Representação gráfica

```{r}
ggplot(table_AOV_medrep, aes(x=variáveis, y=médias)) +
  geom_point(color = "#9e2a2b",size = 4) +
  geom_line(group = 1,linetype = "dashed") +
  labs(title = "ANOVA POR MEDIDAS REPETIDAS",
       x = "Medidas Repetidas", 
       y = "Médias",
       caption = 'OBS: Gráfico construído com base em dados simulados',
       tag = "Estatística no R")
```

# ANOVA de medidas repetidas com grupo controle

Um projeto mais robusto utilizaria que o anterior utilizaria um grupo controle para poder comparar a eficácia do programa entre dois grupos, um que passa pelo programa (grupo experimental) e outro que não passa (grupo controle).
Para **simular** essa situação, vamos criar o seguinte **banco de dados fictício**:

### Geração de um banco de dados

```{r}
# Criação de variáveis, sendo a o grupo controle e b o grupo experimental.

v1a <- round(rnorm(n=50, mean = -1.2, sd = 1.0),digits = 3)
v1b <- round(rnorm(n=50, mean = -1.3, sd = 1.1),digits = 3)
v2a <- round(rnorm(n=50, mean = -1.3, sd = 0.9),digits = 3)
v2b <- round(rnorm(n=50, mean = -0.7, sd = 1.1),digits = 3)
v3a <- round(rnorm(n=50, mean = -1.1, sd = 1.0),digits = 3)
v3b <- round(rnorm(n=50, mean = -0.1, sd = 0.9),digits = 3)
v4a <- round(rnorm(n=50, mean = -1.2, sd = 1.0),digits = 3)
v4b <- round(rnorm(n=50, mean =  0.4, sd = 1.1),digits = 3)
v5a <- round(rnorm(n=50, mean = -1.1, sd = 1.1),digits = 3)
v5b <- round(rnorm(n=50, mean =  0.5, sd = 0.9),digits = 3)

# Junção das variáveis "a" num grupo ctrl
ctrl <- data.frame(v1a,v2a,v3a,v4a,v5a,grupo = "ctrl")

# junção das variáveis "b" num grupo expe
expe <- data.frame(v1b,v2b,v3b,v4b,v5b,grupo = "expe")

# modificação dos nomes das variáveis do grupo expe para ficar igual às variáves do grupo ctrl
# esse passo é necessário para posteriormente juntar esses dois dataframes.
expe <- rename(expe,v1a = v1b,v2a=v2b,v3a=v3b,v4a=v4b,v5a=v5b)

# junção dos dataframes ctrl e expe
df_aov_mr2 <- bind_rows(ctrl,expe)

# transformação da variável grupo em fator
df_aov_mr2$grupo <- as.factor(df_aov_mr2$grupo)

# inserção de uma variável id ao dataframe df_aov_mr2
df_aov_mr2 <- cbind(id = paste("s",1:100,sep = ""),df_aov_mr2)

# renomear as variáveis do dataframe df_aov_mr2 para ficar mais simples
df_aov_mr2 <- rename(df_aov_mr2,v1=v1a,v2=v2a,v3=v3a,v4=v4a,v5=v5a)

# transformação da variável id em fator
# passo necessário para rodar a análise posteriormente
df_aov_mr2$id <- factor(df_aov_mr2$id)

glimpse(df_aov_mr2)
```

### Transformações no banco de dados

Proceder a transformação do banco de dados do formato amplo para o formato longo, de forma semelhante ao que foi feito com o banco de dados `df_aov_mr1`.

```{r}
# Modificação do formato com a função pivot_longer do tidyr
df_aov2 <- 
df_aov_mr2 %>% pivot_longer(cols = 2:6,            # variáveis a serem unidas em uma só.  
                           names_to = "tempo",    # nome dessa nova variável 
                           values_to = "valores") # valores correspondentes à nova variável 

df_aov2$tempo <- as.factor(df_aov2$tempo)

glimpse(df_aov2)
```

### ANOVA de medidas repetidas

Com o banco de dados no formato longo já é possível rodar o modelo da ANOVA.

```{r}
mod_df_aov2 <- ez::ezANOVA(data = df_aov2,    # banco de dados no formato longo
                           dv = valores,        # variável dependente
                           wid = id,          # variável que identifica os sujeitos
                           within = tempo,    # variável intragrupo
                           between = grupo,   # variável entre grupos (ctrl / expe)
                           detailed = TRUE,   # opção para output mais detalhado
                           type = 3)          # opção pelo método da soma dos quadrados

mod_df_aov2    # printar os resultados
```

### Visualização dos dados em tabela

Os resultados da ANOVA indicam se houve efeito intra e entre grupos, mas não diz em que direção essas diferenças ocorreram.
Para isso, é necessário observar as estatísticas descritivas (especialmente as médias) dos grupos.

```{r}
# construção de um dataframe para visuação das estatísticas descritivas
tab_df_aov_mr2 <- 
data.frame(variáveis = names(df_aov_mr2[,2:6]),
           M_ctrl = c(round(mean(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v1),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v2),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v3),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v4),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v5),digits = 2)),
           sdctrl = c(round(sd(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v1),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v2),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v3),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v4),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "ctrl",]$v5),digits = 2)),
           M_expe = c(round(mean(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v1),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v2),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v3),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v4),digits = 2),
                      round(mean(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v5),digits = 2)),
           sdexpe = c(round(sd(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v1),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v2),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v3),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v4),digits = 2),
                      round(sd(df_aov_mr2[df_aov_mr2$grupo == "expe",]$v5),digits = 2)))

tab_df_aov_mr2 %>% pander()
```

### Representação gráfica

```{r}
ggplot(data = df_aov2, aes(x = tempo, y = valores, group = grupo, color = grupo)) +
  geom_line(stat = "summary", size = 1) +
  geom_point(stat = "summary", fun.y = "mean", size = 3) + 
  labs(title = "Efeito de uma intervenção ao longo do tempo",
       x = "Medidas repetidas",
       y = "Valor",
       caption = 'OBS: Gráfico construído com base em dados simulados',
       tag = "Estatística no R")



```

Relato de resultados: Foram realizadas comparações intragrupo (medidas repetidas) e comparações entre grupos (controle e experimental).
Notou-se que houve diferença estatisticamente significativa intragrupo (F~(gl=4,N=100)~=9,489989; p-valor=2.481601e-07) e entre grupos ((F~(gl=1,N=100)~=112.127948; p-valor=6.401131e-18)).

# Exercícios

1.  Utilizando o dataframe `dataset`, verifique se há efeito de sexo (sex) em ansiedade (bai_sum) e depressão (bdi_sum). Observe os dados e escolha a estatística mais apropriada para esse tipo de dado.

Ansiedade - ordinal
Depressão - ordinal
Sexo - nominal (2 categorias: masculino e feminino, independentes)
A estatística mais adequada para essas variáveis é o t-teste.
```{r}
# Ansiedade

## Primeiro passo: verificar se há homogeneidade de variâncias
car::leveneTest(bai_sum ~ sex, dataset, center=mean)

## Segundo passo: calcular o t-teste
t.test(bai_sum ~ sex, dataset, var.equal = FALSE)


## Terceiro passo: Cálculo do tamanho de efeito
effsize::cohen.d(bai_sum ~ sex, data = dataset)

# Depressão

# Primeiro passo: verificar se há homogeneidade de variâncias
car::leveneTest(bdi_sum ~ sex, dataset, center=mean)

## Segundo passo: calcular o t-teste
t.test(bdi_sum ~ sex, dataset, var.equal = TRUE)

## Terceiro passo: Cálculo do tamanho de efeito
effsize::cohen.d(bdi_sum ~ sex, data = dataset)
```

2.  Em relação ao exercício anterior, represente a ansiedade em tabela e a depressão em forma de gráfico.

```{r}
# Ansiedade
tableby(sex ~ bai_sum,
        test = FALSE,
        data = dataset) %>%
  summary(text = TRUE)

# Depressão

dataset %>% drop_na(sex) %>% 
ggplot(aes(x=sex, y=bai_sum)) +
  geom_bar(stat = "summary", 
           fun = mean, 
           color = 'black',
           size = 1, 
           na.rm = TRUE) +
  labs(title = "DEPRESSÃO X SEXO",
       x = "SEXO", 
       y = "DEPRESSÃO",
       caption = 'Estatística no R',
       tag = "NEAP")
```

3.  Utilizando o mesmo dataframe, verifique se há diferenças entre países (country) em ansiedade (bai_sum) e depressão (bdi_sum). Observe os dados e escolha a estatística mais apropriada para esse tipo de dado.

```{r}
aov_ans_país <- aov(bai_sum ~ country, dataset)
aov_dep_país <- aov(bdi_sum ~ country, dataset)

# visualização dos resultados
summary(aov_ans_país)
summary(aov_dep_país)

dataset %>% group_by(country) %>% summarise(ansiedade = mean(bai_sum, na.rm = TRUE),
                                            depressão = mean(bdi_sum, na.rm = TRUE))
                                    
```

4.  Em relação ao exercício anterior, represente a ansiedade em tabela e a depressão em forma de gráfico.

5.  Execute o código abaixo para gerar o dataframe `df_ex` e realize uma ANOVA de medidas repetidas com esse dataframe.
    Note que `df_ex` está no **formato amplo**.

```{r}
df_ex <- data.frame(id = paste("s",1:80,sep = ""),
                    v1 = round(rnorm(n=80, mean = 20, sd = 3),digits = 2),
                    v2 = round(rnorm(n=80, mean = 22, sd = 3),digits = 2),
                    v3 = round(rnorm(n=80, mean = 26, sd = 3),digits = 2),
                    v4 = round(rnorm(n=80, mean = 27, sd = 3),digits = 2),
                    v5 = round(rnorm(n=80, mean = 27, sd = 3),digits = 2))
```

```{r}
df_ex_longer <- df_ex %>% pivot_longer(cols = 2:6, # variáveis a serem unidas em uma só.  
                           names_to = "medidas", # nome dessa nova variável 
                           values_to = "valores") # valores correspondentes à nova variável 

# transformar as variáveis id e tempo em fatores

df_ex_longer$id <- factor(df_ex_longer$id)
df_ex_longer$medidas <- factor(df_ex_longer$medidas)

glimpse(df_ex_longer)

mod_df_ex_longer <- ez::ezANOVA(data = df_ex_longer,    # banco de dados no formato longo
                                dv = valores,             # variável dependente
                                wid = id,                 # variável que identifica os sujeitos
                                within = medidas,           # variável intra-sujeitos
                                detailed = TRUE,          # saída mais detalhada
                                type = 3)                 # tipo de soma dos quadrados, default 2
```
