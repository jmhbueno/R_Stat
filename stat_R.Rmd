---
title: "Estatística no R"
author: "Maurício Bueno"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

Esta disciplina tem como objetivo aprender a realizar análises estatísticas mais empregadas em pesquisas em psicologia, no ambiente de programação R.
Inicialmente, vamos carregar (`install.packages()) e ativar (library()`) os pacotes que iremos utilizar na disciplina.

# Carregamento dos pacotes

```{r}
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(psych)) install.packages("psych")
if(!require(knitr)) install.packages("knitr")
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(expss)) install.packages("expss")
if(!require(janitor)) install.packages("janitor")
if(!require(pander)) install.packages('pander')
if(!require(arsenal)) install.packages('arsenal')
if(!require(moments)) install.packages('moments')
if(!require(readr)) install.packages('moments')
if(!require(readxl)) install.packages('readxl')
if(!require(descr)) install.packages("descr")
if(!require(rcompanion)) install.packages("rcompanion")
if(!require(rstatix)) install.packages("rstatix")
# Ativação dos pacotes ====

library(tidyverse)
library(pander)
library(janitor)
library(psych)
library(knitr)
library(arsenal)
library(rstatix)
library(GPArotation)
# library(kableExtra)
# library(expss)
# library(readxl)
# library(readr)
# library(corrplot)
```

# Importar banco de dados

Inicialmente vamos trabalhar com o banco de dados `dataset_mapfre.csv`, clique [aqui](https://docs.google.com/spreadsheets/d/1G0lQKeU0atMk3Q4wO5zz4HdvReRxKS68vx_Q0WbB37A/edit?usp=sharing) para baixá-lo.
Esse banco de dados se refere ao artigo "[Sintomas de depressão e ansiedade em uma amostra representativa de universitários espanhóis, portugueses e brasileiros](https://drive.google.com/file/d/1qa0iCDm2DRvh3M6a2k7ENGahceDAlPIg/view?usp=sharing)".
Sugere-se a leitura desse artigo para a compreensão dos dados.

```{r}
dataset <- read.csv("dataset_mapfre.csv",encoding="UTF-8",stringsAsFactors=TRUE)

# OBS: Para que este comando funcione, é necessário que o arquivo csv esteja no diretório de trabalho do R.

# Observar o banco de dados
glimpse(dataset)
```

# Estatística descritiva

## Frequências

```{r}

# Função count()
dataset %>% 
  filter(!is.na(sex)) %>% 
  group_by(sex) %>% 
  count(country) %>% 
  mutate(porc = n/sum(n)*100) %>% 
  pander()

# usando a função tabyl() do pacote janitor
# contar quantas pessoas de cada país.

dataset %>%             # pegar o dataframe dataset
  tabyl(country) %>%    # use a função tabyl para tabular as categorias de país
  pander()              # utilize o pander para fazer a tabela

dataset %>%             # pegar o dataframe dataset
  tabyl(country) %>%    # use a função tabyl para tabular as categorias de país
  adorn_totals() %>%    # acrescente uma linha com os totais
  pander()              # utilize o pander para fazer a tabela

# contar por gênero e país (retirando NAs)
dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(sex,country) %>% 
  adorn_totals() %>% 
  pander()

# contar por gênero e país, acrescentando funções
dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(country,sex) %>%           # função de tabulação do janitor
  adorn_totals(c("row","col")) %>% # adiciona o N
  adorn_percentages("row") %>%     # adiciona porcentagens
  adorn_pct_formatting(
    rounding = "half up",          # arredondar do cinco pra cima
    digits = 0) %>%                # número de casas decimais
  adorn_ns() %>%                   # mostra N e % juntas
  pander()                         # melhora a visualização dos dados.

# adição de um qui-quadrado para a distribuição
# para rodar essa análise tem que tirar os totais.

# dataset %>% 
  # filter(!is.na(sex)) %>% 
  # tabyl(country,sex) %>%           # função de tabulação do janitor
  # adorn_totals(c("row","col")) %>% # adiciona o N
  # chisq.test()
  # pander()                         # melhora a visualização dos dados.
```

#### Exercício

Utilize o dataframe `dataset` para realizar os exercícios abaixo:

1.  Crie uma tabela de frequências dos cursos (grado) dos participantes.

2.  Crie uma tabela de frequências dos cursos dos participantes, por sexo, com totais.

```{r message=FALSE, warning=FALSE, include=FALSE}
dataset %>%
  tabyl(grado) %>%  
  adorn_totals() %>%
  pander()          

dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(grado,sex) %>%           
  adorn_totals(c("row","col")) %>% 
  adorn_percentages("row") %>%     
  adorn_pct_formatting(rounding = "half up", digits = 0) %>% 
  adorn_ns() %>%
  pander()      
```

## Medidas de tendência central e de dispersão

A descrição dos dados geralmente é realizada pelas seguintes estatísticas: Média, desvio padrão, mediana, amplitude, mínimo, máximo, assimetria e curtose.
Para calculá-las podemos usar funções específicas para cada uma ou funções que realizam um conjunto de análises descritivas.

### Funções específicas

```{r}

## mean()
mean(dataset$age, na.rm = TRUE)

## sd()
sd(dataset$age, na.rm = TRUE)

## median()
median(dataset$age, na.rm = TRUE)

## min()
min(dataset$age, na.rm = TRUE)

## max()
max(dataset$age, na.rm = TRUE)

## range()
range(dataset$age, na.rm = TRUE)

## skewness()
moments::skewness(dataset$age, na.rm = TRUE) # pacote moments 
skew(dataset$age, na.rm = TRUE)              # pacote psych

## kurtosis()
moments::kurtosis(dataset$age, na.rm = TRUE) # pacote moments
kurtosi(dataset$age, na.rm = TRUE)           # pacote psych
```

#### Exercícios

Calcule as estatísticas descritivas: média, desvio padrão, mediana, valores mínimo e máximo, amplitude, assimetria e curtose das pontuações em depressão (bdi_sum) e ansiedade (bai_sum).
Crie uma tabela (dataframe) com esses valores.

```{r include=FALSE}
# média
mean(dataset$bdi_sum, na.rm = TRUE)
mean(dataset$bai_sum, na.rm = TRUE)

# desvio padrão
sd(dataset$bdi_sum, na.rm = TRUE)
sd(dataset$bai_sum, na.rm = TRUE)

# mínimo
min(dataset$bdi_sum, na.rm = TRUE)
min(dataset$bai_sum, na.rm = TRUE)

# máximo
max(dataset$bdi_sum, na.rm = TRUE)
max(dataset$bai_sum, na.rm = TRUE)

# amplitude
range(dataset$bdi_sum, na.rm = TRUE)
range(dataset$bai_sum, na.rm = TRUE)

# assimetria
moments::skewness(dataset$bdi_sum, na.rm = TRUE) # assimetria positiva (rabo para a direita)
skew(dataset$bdi_sum, na.rm = TRUE)
moments::skewness(dataset$bai_sum, na.rm = TRUE) # assimetria positiva (rabo para a direita)
skew(dataset$bai_sum, na.rm = TRUE)

# curtose
moments::kurtosis(dataset$bdi_sum, na.rm = TRUE) # curva leptocúrtica (pontuda)
kurtosi(dataset$bdi_sum, na.rm = TRUE) # curva leptocúrtica (pontuda)

moments::kurtosis(dataset$bai_sum, na.rm = TRUE) # curva leptocúrtica (pontuda)
kurtosi(dataset$bai_sum, na.rm = TRUE) # curva leptocúrtica (pontuda)

# Tabela

data.frame(Estatísticas =       # data.frame() é a função para criar uma tabela ou planilha
             c("Média",         # eu quero três colunas: estatísticas, depressão e ansiedade
               "Desvio Padrão", # então, precisamos definir o que vai aparecer em cada coluna   
               "Mínimo",
               "Máximo",
               "Assimetria",
               "Curtose"),
           Depressão = 
             c(mean(dataset$bdi_sum, na.rm = TRUE),
               sd(dataset$bdi_sum, na.rm = TRUE),
               min(dataset$bdi_sum, na.rm = TRUE),
               max(dataset$bdi_sum, na.rm = TRUE),
               moments::skewness(dataset$bdi_sum, na.rm = TRUE),
               moments::kurtosis(dataset$bdi_sum, na.rm = TRUE)),
           Ansiedade = 
             c(mean(dataset$bai_sum, na.rm = TRUE),
               sd(dataset$bai_sum, na.rm = TRUE),
               min(dataset$bai_sum, na.rm = TRUE),
               max(dataset$bai_sum, na.rm = TRUE),
               moments::skewness(dataset$bai_sum, na.rm = TRUE),
               moments::kurtosis(dataset$bai_sum, na.rm = TRUE))) %>% 
  pander()
```

# Distribuição normal

A distribuição normal (ou distribuição de Gauss) é uma distribuição de probabilidades, isto é ela indica a probabilidade de um certo valor ser obtido.
Uma **distribuição normal padrão** apresenta médial igual a zero e desvio padrão igual a 1.
A média fica no centro da distribuição e coincide com a mediana, separando a amostra em duas metades.
Quando a curtose (achatamento) e assimetria (distribuição lateral) são diferentes de zero, a distribuição começa a se afastar da normal.

```{r eval=FALSE, include=FALSE}
distalea <- runif(n=100000, min=1, max=5)
hist(distalea)
mean(distalea)
sd(distalea)
# Extrai os percentis de uma variável
# punif(big_five_BR$extr,min = 1,max = 5) * 100

# Retirar 40 amostras da população distalea, calcular as médias e montar uma lista
distalea_mean_list <- c(mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)),
                        mean(sample(distalea, 100, replace = FALSE)))

hist(distalea_mean_list)

# Criar / Extrair amostra com valores inteiros

sample(
  x = 1:5,
  size = 1000,
  replace = TRUE) %>% hist()

# usando a função rnorm() para gerar dados aleatórios 
# rnorm(n, mean = 10, sd = 2)

# gerar 
distnorm <- rnorm(100000, mean = 10, sd = 2)
mean(distnorm)
sd(distnorm)
hist(distnorm, breaks = 50)
range(distnorm)
skew(distnorm)
kurtosi(distnorm)

sample(distnorm,          # nome do arquivo
       100,               # número de observações que se deseja extrair
       replace = FALSE)   # False indica que a amostra será extraída sem reposição.


s1 <- sample(distnorm, 100, replace = FALSE)
s2 <- sample(distnorm, 100, replace = FALSE)
s3 <- sample(distnorm, 100, replace = FALSE)
s4 <- sample(distnorm, 100, replace = FALSE)
s5 <- sample(distnorm, 100, replace = FALSE)
s6 <- sample(distnorm, 100, replace = FALSE)
s7 <- sample(distnorm, 100, replace = FALSE)
s8 <- sample(distnorm, 100, replace = FALSE)
s9 <- sample(distnorm, 100, replace = FALSE)
s10 <- sample(distnorm, 100, replace = FALSE)
s11 <- sample(distnorm, 100, replace = FALSE)
s12 <- sample(distnorm, 100, replace = FALSE)
s13 <- sample(distnorm, 100, replace = FALSE)
s14 <- sample(distnorm, 100, replace = FALSE)
s15 <- sample(distnorm, 100, replace = FALSE)
s16 <- sample(distnorm, 100, replace = FALSE)
s17 <- sample(distnorm, 100, replace = FALSE)
s18 <- sample(distnorm, 100, replace = FALSE)
s19 <- sample(distnorm, 100, replace = FALSE)
s20 <- sample(distnorm, 100, replace = FALSE)

mean(s1 )
mean(s2 )
mean(s3 )
mean(s4 )
mean(s5 )
mean(s6 )
mean(s7 )
mean(s8 )
mean(s9 )
mean(s10)
mean(s11)
mean(s12)
mean(s13)
mean(s14)
mean(s15)
mean(s16)
mean(s17)
mean(s18)
mean(s19)
mean(s20)

médias <- c(mean(s1),mean(s2),mean(s3),mean(s4),mean(s5),mean(s6),mean(s7),mean(s8),mean(s9), mean(s10),mean(s11),mean(s12),mean(s13),mean(s14),mean(s15),mean(s16),mean(s17),mean(s18),mean(s19), mean(s20))

mean(médias)
sd(médias)
hist(médias,breaks = 5)

mean(médias) - sd(médias) # um desvio abaixo da média
mean(médias) - 2*sd(médias) # dois desvios abaixo da média

mean(médias) + sd(médias) # um desvio abaixo da média
mean(médias) + 2*sd(médias) # dois desvios abaixo da média

#mean(c(mean(s1),mean(s2),mean(s3),mean(s4),mean(s5),mean(s6),mean(s7),mean(s8),mean(s9), mean(s10)))
#sd(c(mean(s1),mean(s2),mean(s3),mean(s4),mean(s5),mean(s6),mean(s7),mean(s8),mean(s9), mean(s10)))
```

# Funções que sumariam dados

```{r}
# describe() {psych}
describe(dataset$age, na.rm = TRUE) %>% pander()
describe(dataset$age, na.rm = TRUE) %>% kable(format = "markdown")

# summary() {base}
dataset %>% select(age) %>% summary()

# tableby() {arsenal}
tableby(country ~ bdi_sum + bai_sum, # calcule as descritivas de bdi e bai por country 
        test = FALSE,                # se FALSE,  não faz teste de significância 
        data = dataset) %>%          # especificar base de dados
  summary(text=TRUE)                 # tem que colocar text=TRUE senão aparecem uns códigos estranhos porque o R entende o espaço como código.                                            Assim a tabela fica bacaninha.

## mesma função mas para a variável sexo.
tableby(sex ~ bdi_sum + bai_sum,
        test = FALSE,
        data = dataset) %>% 
  summary(text=TRUE)

## Pode descrever apenas uma variável em função de sexo
tableby(sex ~ age, data = dataset) %>% summary(text = TRUE)

## Pode descrever somenta a variável contínua sem ser em função de alguma outra variável.
tableby( ~ age + bdi_sum + bai_sum, data = dataset) %>% summary(text = TRUE)

## Também pode dar as médias em função do sexo, estratificado por país
tableby(sex ~ age + bdi_sum + bai_sum, data = dataset, strata = country) %>% summary(text = TRUE)

## ou o contrário
tableby(country ~ age + bdi_sum + bai_sum, data = dataset, strata = sex) %>% summary(text = TRUE)

## Interação entre variáveis nominais

tableby(interaction(sex, country) ~ bdi_sum + bai_sum,
        test = FALSE,
        data = dataset) %>% 
  summary(text = TRUE)
```

# Representações gráficas

### Gráficos de barras

```{r}
ggplot(dataset, aes(x = country)) + 
  geom_bar() + 
  labs(x = "país",
       title = "Número de participantes nos países investigados")

# alterando o eixo y para ser a % ao invés do N
ggplot(dataset, aes(x = country, y = ..prop.., group = 1)) + 
  geom_bar(stat = "count",fill = "dodgerblue4") +
  geom_text(aes(label = scales::percent(round(..prop..,2)),
                y = ..prop..),
            stat = "count", 
            color = "white",
            size = 5, 
            position = position_stack(vjust = 0.5)) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "país",
       y = "porcentagem",
       title = "Número de participantes nos países investigados")

# Alterando argumentos
ggplot(dataset, 
       aes(x=country, y=bai_sum)) +
  geom_bar(stat = "summary", 
           fun = mean, 
           fill = "dodgerblue", 
           color = "black",
           na.rm = TRUE) + 
  labs(title = "Média de Ansiedade por país",
       x = "País", y = "Média de Ansiedade (BAI)")

# adicionando outros elementos ao gráfico (barras de erro)
ggplot(dataset, 
       aes(x=country, y=bai_sum)) +
  geom_bar(stat = "summary", 
           fun = mean, 
           fill = "violet", 
           color = "black",
           na.rm = TRUE) + 
  stat_summary(geom = "errorbar", fun.data = mean_se,width = 0.5) +
  labs(title = "Média de Ansiedade por país",
       x = "País", y = "Média de Ansiedade (BAI)")

# se modificar a posição do argumento fill, para dentro de aes e com o critério country... o gráfico fica colorido por país.
ggplot(dataset, 
       aes(x=country, y=bai_sum,fill = country)) +
  geom_bar(stat = "summary", 
           fun = mean, 
           color = "black",
           na.rm = TRUE) + 
  stat_summary(geom = "errorbar", fun.data = mean_se,width = 0.5) +
  labs(title = "Média de Ansiedade por país",
       x = "País", y = "Média de Ansiedade (BAI)")
```

### Gráfico de setor (polar, pizza ou torta)

```{r}
dataset %>% 
  count(country) %>% 
  mutate(pct = n/sum(n)) %>% 
  ggplot(.,aes(x = "", y = pct, fill = country)) + 
  geom_col(color = "black") + 
  geom_text(aes(label = scales::percent(round(pct,3))),
            position = position_stack(vjust = 0.5)) + 
  coord_polar(theta = "y") + 
  labs(title = "Proporção de participantes em cada país")
```

### Gráficos para descrição de distribuição ou variabilidade

```{r}
# Histograma
ggplot(data = dataset, aes(x = age)) + 
  geom_histogram(bins = 30,color = "black", fill = "#61988E") + 
  labs(y = "Frequência",
    title = "Distribuição da idade dos participantes")

# Densidade
ggplot(data = dataset, aes(age)) + 
  geom_density(fill = "#56b4e9") + 
  labs("Distribuição da idade dos participantes")

# Boxplot (diagrama de caixa e bigode)
## Uma variável continua
ggplot(data = dataset, aes(y=age,x="")) +
  geom_boxplot(fill = "#56b4e9") + 
  labs(title = "Distribuição da idade dos participantes")

## uma variável continua e uma categórica (discreta)
## no caso, bai_sum por país.
ggplot(dataset,aes(x=country, y=bai_sum)) +
  geom_boxplot(color = "black", fill = "#74c69d") + 
  labs(title = "Distribuição das Pontuações no BAI, por país")


# Combinação de gráficos usando o grid.arrange do pacote gridExtra

gridExtra::grid.arrange(
  
# Gráfico 1
ggplot(data = dataset, aes(age)) + 
  geom_histogram(aes(y=..density..), alpha = 0.5, position = "identity") +
  geom_density(alpha = 0.8, fill = "#56b4e9") + 
  labs("Distribuição da idade dos participantes"),
# Gráfico 2
ggplot(data = dataset, aes(y=age,x="")) +
  geom_boxplot(fill = "#56b4e9") + 
  labs(x = "") +
  coord_flip(),
top = "Distribuição da idade dos participantes"
)
```

### Gráficos de pontos

```{r}
ggplot(dataset, aes(x=age, y=bai_sum)) +
  geom_point(color = "#9e2a2b") +
  labs(title = "Idade x Ansiedade",
       x = "Idade", y = "Ansiedade (BAI)")

ggplot(dataset, aes(x=age, y=bai_sum)) +
  geom_jitter(color = "#9e2a2b") +
  labs(title = "Idade x Ansiedade",
       x = "Idade", y = "Ansiedade (BAI)")

# com a reta de regressão
ggplot(dataset, aes(x=age, y=bai_sum)) +
  geom_jitter(color = "#9e2a2b") +
  geom_smooth(method = "lm") +
  labs(title = "Idade x Ansiedade",
       x = "Idade", y = "Ansiedade (BAI)")

# ansiedade x depressão
  
ggplot(dataset, aes(x=bai_sum, y=bdi_sum)) +
  geom_jitter(color = "#9e2a2b") +
  geom_smooth(method = "lm") +
  labs(title = "Depressão x Ansiedade",
       x = "Depressão (BDI)", y = "Ansiedade (BAI)")

# colocar os dois gráficos juntos na mesma imagem

gridExtra::grid.arrange(
  
  #Gráfico 1
  
  ggplot(dataset, aes(x=age, y=bai_sum)) +
  geom_point(color = "#9e2a2b") +
  labs(title = "Idade x Ansiedade",
       x = "Idade", y = "Ansiedade (BAI)"),

  # Gráfico 2
ggplot(dataset, aes(x=age, y=bai_sum)) +
  geom_jitter(color = "#9e2a2b") +
  labs(title = "Idade x Ansiedade",
       x = "Idade", y = "Ansiedade (BAI)"),
nrow = 1    # sem esse comando, os gráficos ficam 2 linhas
)

dataset %>% 
filter(!is.na(sex)) %>% 
  ggplot(.,aes(x = age, y = bai_sum, color = sex)) +
  geom_jitter() +
  geom_smooth(method = "lm")

dataset %>% 
  filter(!is.na(sex), !is.na(curso_ou_ano)) %>% 
  ggplot(., aes(x = age, y=bai_sum,
                fill = factor(curso_ou_ano),
                color = sex,
                shape = country)) + 
  geom_jitter() +
  geom_smooth(method = "lm")
         
```

# Análises de associação entre variáveis

Muitas vezes, o pesquisador está interessado no estudo ou análise de relações entre variáveis.
Nesses casos, ele recorrerá a estatísticas como o teste de qui-quadrado (caso tenha variáveis do tipo nominal ou categórica), coeficiente de correlação de Pearson ou regressão linear quando as variáveis forem contínuas.

## Testes de Qui-Quadrado

O teste de qui-quadrado é uma medida de associação entre variáveis categóricas, das quais só temos a frequência de ocorrência.
Existem três tipos de testes de qui-quadrado:

-   de aderência: quando se deseja verificar as distribuições de probabilidades de cada categoria de uma variável em relação a um valor teórico esperado.

-   de homogeneirdade: quando se deseja verificar se as distribuições das categorias são as mesmas para diferentes subpopulações de interesse.

-   de independência: verficiar se duas variáveis categóricas são independentes

Neste caso, vamos fazer uma análise de qui-quadrado de independência, a mais comumumente utilizada, para verificar se há uma associação entre país e sexo dos participantes do banco de dados dataset.
O primeiro passo para isso é montar uma tabela de contingência.

### Tabela de Contingência

Nesse caso, vamos usar a função da base `table()` para gerar uma tabela 2 x 3, duas linhas e três colunas, em que as linhas representarão os sexos masculino e feminino, e as colunas representarão os países: Brasil, Portugal e Espanha.

```{r}
tabcont_sex_country <- table(dataset$sex,dataset$country)

```

O próximo passo é realizar a análise de qui-quadrado em si.

### Análise de qui-quadrado.

```{r}
# É bom salvá-la em um objeto porque tem mais informações do que as que são mostradas na análise.
options(scipen = 999) # função para tirar a notação científica de potência.
chi_sex_country <- chisq.test(tabcont_sex_country)

# Pressuposto: frequências esperadas > 5
###chi_sex_country$expected
###round(chi_sex_country$expected,0)

# Análise dos resíduos
## Resíduo padronizado ou resíduo de Pearson
###chi_sex_country$residuals

## Resíduo padronizado ajustado (mais usado) - 
### Estão padronizados em z. 
### Portanto, valores > 1.96 ou < -1.96 são considerados valores significativos para p/ alfa de 5%
### ou seja, cujos resíduos encontrados são maiores do que os esperados.
###chi_sex_country$stdres

# Alguns autores recomendam um ajuste na análise do resíduo em função do tamanho da tabela de contingência
# Assim, novo_sig = 0,05/(n_linhas * n_colunas)
# a nova formula para calcular o índice de significância é:
new_alfa <- 0.05/(nrow(tabcont_sex_country)*ncol(tabcont_sex_country))

# calcular os pontos de corte em z para o novo valor de alfa (new_alfa)
###qnorm(0.05/2)       # valor de z correspondente a um alfa de 5%, que dá o 1,96
###qnorm(new_alfa/2)   # z relativo ao new_alfa: > 2,64 ou < -2,64, para alfa=0,83%
                    # Usar esse valor para avaliar os resíduso padr. ajustados
                    # com o novo valor de z, os resultados continuam significativos.
# uma opção seria calcular o p para todos os resíduos
###options(scipen = 0)
###2*(1-pnorm(abs(chi_sex_country$stdres)))

# Tamanho do efeito
# phi é usado para tabelas 2 x 2
# V de Cramer é usado para tabelas maiores
# usando a função cramer_v() do rstatix
cramer_v(tabcont_sex_country)

# A interpretação do V de Cramer depende dos graus de liberdade do teste
# gl = (linhas -1) * (colunas-1)
# Messe caso gl=2 e o V de Cramer corresponde a um tamanho de efeito pequeno (Cohen, 1988).
# O V de Cramer varia de 0 a 1. Valores baixos e altos correspondem a efeitos pequenos e grandes, respectivamente.

# para calcular o phi (tamanho de efeito para tabelas 2 x 2)
# phi(tabela_de_contingência)
```

Nesse caso, o valor de p foi igual a 3.003e-11 (lê-se 3.003 x 10^-11^).
A interpretação do V de Cramer depende dos graus de liberdade empregada na análise.
Como essa análise foi realizada sobre uma distribuição 2 x 3, o número de graus de liberdade é igual a 2 (gl = (linhas -1) \* (colunas-1)).

```{r echo=FALSE}
data.frame("Graus de Liberdade" = c(1,2,3),
           Pequeno = c(0.1,0.07,0.06),
           Médio = c(0.3,0.21,0.17),
           Grande = c(0.5,0.35,0.29)) %>% pander()
```

Nesse caso, o valor de p foi menor que 0,05, indicando que há associação entre o sexo do participantes e o diagnóstico de TDAH.
Essa associação diz que ser do sexo masculino aumenta as chances de receber uma diagnóstico de TDAH.
No entanto, o tamanho do efeito foi pequeno.

### Representação gráfica

```{r}
corrplot::corrplot(chi_sex_country$stdres,  # função para representação em cores
                   is.corr = FALSE,         # não se trata de correlações
                   method = "color",        # método para pintar o quadrado todo.
                   tl.col = "black",        # textos na cor preta
                   tl.srt = 0)              # angulação das colunas, 90 é vertical.

ggplot(dataset, aes(x = country, fill = sex)) +
  geom_bar(position = "fill") +
  coord_flip() +
  labs(title = "Proporção Sexo x País",
       x = "País", y = "Proporção", fill = "Sex")
```

### Exercícios sobre qui-quadrado

1.  Calcular o qui-quadrado para verificar as associações entre sexo e ansiedade (bai_class)

2.  Calcular o qui-quadrado para verificar as associações entre sexo e depressão (bai_class)

Dica: para que as categorias de ansiedade e depressão sejam mostradas em ordem crescente (mínima, leve, moderada, grave), é necessário informar o R disso por meio do argumento `levels`da função `factor`.

```{r include=FALSE}

# colocando as variáveis bdi_class e bai_class em ordem, usando o levels
summary(dataset$country)
summary(dataset$sex)
summary(dataset$bdi_class)
summary(dataset$bai_class)

# padronizar a ordem dos níveis: minima, leve, moderada, grave.
dataset$bdi_class <- factor(dataset$bdi_class,
                            levels = c("minima",
                                       "leve",
                                       "moderada",
                                       "grave"))

dataset$bai_class <- factor(dataset$bai_class,
                            levels = c("minima",
                                       "leve",
                                       "moderada",
                                       "grave"))
```

## Coeficientes de correlação (Pearson, Spearman e Kendall)

Quando o interesse do pesquisador é investigar o grau de associação entre variáveis, ele pode empregar o Coeficiente de Correlação de Pearson.
Os resultados dessa análise podem variar de -1 a 1.
Resultados positivos revelam associação diretamente proporcional entre as variáveis, resultados negativos revelam associação inversamente proporcional entre as variáveis e resultados próximos de zero indicam que não há associação entre as variáveis.\
No entanto, antes de realizar a análise é preciso verificar se os dados atendem aos pressupostos da análise.

### Verificação dos pressupostos para a análise

```{r}
# verificação de normalidade
options(scipen = 999)
shapiro.test(dataset$bai_sum)
shapiro.test(dataset$bdi_sum)

## representação gráfica da normalidade (histograma)
hist(dataset$bdi_sum)
hist(dataset$bai_sum)

# presença de outliers
boxplot(dataset$bdi_sum)
boxplot(dataset$bai_sum)

# Relação linear entre as variáveis
plot(dataset$bdi_sum,dataset$bai_sum)

# Análise de resíduos (homocedasticidade)
lm_ans_dep <- lm(bdi_sum ~ bai_sum, dataset)

par(mfrow = c(1,2)) # os números indicam uma linha, duas colunas
plot(lm_ans_dep, which = c(1,3))
# os gráficos mostram os resíduos pelos valores previstos.
# o 1º mostra os resíduos brutos e o 2º ow resíduos padronizados
# Em ambos os casos a linha deve estar paralela a x, o que indica relação linear entre as variáveis.
# Em ambos os casos os pontos devem estar homogeneamente distribuídos ao longo da reta, distribuição de pontos igualitária ao longo da curva (homocedasticidade). A variação dos resíduos tem que ser homogênea ao longo da curva.
# Verificação de outliers quando há resíduos acima de 3 ou abaixo de -3
par(mfrow = c(1,1)) # voltar para um gráfico por vez
```

### Correlação simples entre duas variáveis

Usando o dataframe `dataset`, vamos calcular o coeficiente de correlação entre depressão e ansiedade:

```{r}
# correlação de Pearson (r) com o pacote stats, que é da base do R
options(scipen = 0)
cor.test(dataset$bdi_sum,dataset$bai_sum, method = "pearson") %>% pander()

# correlação de Spearman (rho)
cor.test(dataset$bdi_sum,dataset$bai_sum, method = "spearman") %>% pander()

# correlação de Kendal (Tau)
cor.test(dataset$bdi_sum,dataset$bai_sum, method = "kendall") %>% pander()
```

A maioria das vezes, os pesquisadores querem observar as correlações entre mais de duas variáveis.
Nesses casos, é necessário criar uma matriz de correlações.
Para fazer isso, vamos usar o banco de dados `big_five` e a função `corrplot` do pacote `corrplot`.

### Matriz de correlações

```{r}
# Importar o dataframe big_five
big_five <- readRDS("big_five.rds")

# obter matriz de correlações com a função cor() do stats, da base do R.
matriz_cor <- cor(big_five[,59:63], method = "pearson")

# obter matriz de correlações com a função corr.test(), do pacote psych
matriz_psych <- corr.test(big_five[,59:63], method = "pearson") 

matriz_psych$r
matriz_psych$p
matriz_psych$stars %>% pander()

# matriz de correlações com linhas e colunas diferentes
matriz1 <- corr.test(big_five[,59:63], big_five[,3], method = "pearson")
matriz1$r
matriz1$p
matriz1$stars %>% pander() # esse tipo de matriz não dá pra plotar.
```

### Representação gráfica das correlações

```{r}
ggplot(dataset, aes(x=bdi_sum,y=bai_sum)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Depressão e Ansiedade", 
       x = "Depressão", 
       y = "Ansiedade") +
  theme_classic()

# adicionar informações sobre a curva de regressão

summary(lm_ans_dep) # esse linear model foi rodado no chunk acima
ggplot(dataset, aes(x=bdi_sum,y=bai_sum)) +
  geom_jitter() +
  geom_smooth(method = "lm") +
  labs(title ="Correlação entre Depressão e Ansiedade", 
       x = "Depressão", 
       y = "Ansiedade") +
  theme_classic() + 
  annotate("text",x=20,y=65,label="Adjusted R-squared:  0.3596") + 
  annotate("text",x=20,y=60,label="bai_sum = 4.36700 + 0.57206*bdi_sum")
  

# matriz de correlações usando o corrplot
corrplot::corrplot(matriz_psych$r, 
                   method = "shade",
                   type = "lower",
                   order = "hclust",
                   addCoef.col = TRUE)

# opções de método: "circle", "square", "ellipse", "number", "shade", "color", "pie
# opções de tipo: "lower", "upper", "full"
# opção de ordem: "hclust"- organiza as correlações hierarquicamente
#                 "original" - ordem das variáveis no banco
#                 "AOE" - angular order of eigenvectors
#                 "alphabet" - ordem alfabética
```

### Exercícios sobre correlação

Baixe o banco de dados [rwas_us](https://docs.google.com/spreadsheets/d/1SNsFa2wRxIvSvA4wVsZz_lkKDNry1WbfjwUkgrZf0k8/edit?usp=sharing), que foi empregada em um estudo sobre autoritarismo conservador, e cole-o no mesmo diretório em que você está salvando seus arquivos para este estudo.
Para mais informações sobre as variáveis desse banco de dados, baixe também [este arquivo](https://docs.google.com/document/d/1oOXxYNLe7nd8kkK7QyOKu_2KiDqfO-wuyDuKbB17iz0/edit?usp=sharing).
Importe esse banco de dados para o R.
Note que ele está no formato csv.
Em seguida, use esse banco de dados para realizar os exercício abaixo.

Calcule as correlações (r) e os índices de significância (p) entre os cinco grandes fatores de personalidade (extr, neur, amab, cons e aber).

Calcule as correlações (r) e os índices de significância (p) dos cinco grandes fatores de personalidade (extr, neur, amab, cons e aber) com raciocínio verbal (rv) e autoritarismo (auth), mas expresse os resultados com os traços de personalidade nas linhas e o rv e o auth nas colunas.

Faça um gráfico de pontos para cada par de correlações entre cinco grandes fatores.

Faça um gráfico de calor (heat map) para as correlações entre os cinco grandes fatores.

## Regressão Linear Múltipla

### Carregamento dos pacotes e importação do banco de dados

```{r}

if(!require(car)) install.packages("car")
if(!require(lmtest)) install.packages("lmtest")
if(!require(ggpubr)) install.packages("ggpubr")
if(!require(QuantPsyc)) install.packages("QuantPsyc")
if(!require(scatterplot3d)) install.packages("scatterplot3d")

library(car)
library(lmtest)
library(ggpubr)
library(QuantPsyc)
library(scatterplot3d)

```

### Análise dos pressupostos

```{r}
# selecionar os participantes brasileiros do df big_five.

big_five_BR <- big_five %>% filter(país == "BR")

# rodando a regressão (usando a função lm() do pacote stats (básico do R)
# lm vem de linear model
mod <- lm(idade ~ extr+neur+amab+cons+aber, # big-five predizendo idade
          data=big_five_BR,                 # onde estão os dados
          na.action = na.omit)              # ignorar NAs

## Análise dos pressupostos
par(mfrow = c(2,2))
plot(mod)

### O primeiro gráfico permite avaliar a linearidade. A linha vermelha tem que estar aproximadamente horizontal para o modelo ser linear.
### O segundo gráfico permite verificar se os resíduos apresentam distribuição normal (Q-Q plot). No eixo y os resíduos encontrados e no eixo x os resíduos que seriam esperados caso a distribuição fosse de fato normal. O esperado é que os pontos caiam sobre a linha pontilhada.
### O terceiro gráfico avalia homocedasticidade. Para que haja homocedasticidade (desejável) os pontos têm que estar distribuídos aleatoriamente pelo retângulo do gráfico e não formando um triângulo. Ou seja, os resíduos têm que ser aleatórios e não correlacionados entre si.
### No quarto gráfico é possível verificar a existência de outliers e pontos influentes. Caso existam outliers haverá pontos para fora da linha pontilhada vermelha. Os resíduos padronizados devem estar entre -3 e +3 (eixo y).

par(mfrow = c(1,1))   # voltar para 1 gráfico por página.

## normalidade dos resíduos usando o pacote stats
options(scipen = 999)
shapiro.test(mod$residuals)

## Outliers nos resíduos
summary(rstandard(mod)) # os resultados devem estar entre -3 e +3

## Teste de Durbin-Watson
durbinWatsonTest(mod)
### não há autocorrelação entre os resíduos quando o valor da estatística está próximo a 2 (entre 1,5 e 2,5, ou entre 1 e 3)

## Homocedasticidade (Breusch-Pagan) ou homogeneidade das variâncias
bptest(mod)   # o valor de p > 0,05 indica que há homocedasticidade

## Ausência de multicolinearidade
names(big_five_BR)
pairs.panels(big_five_BR[,59:63]) # há multicolinearidade quando r > 0.9

vif(mod)   
### há problema de multicolinearidade quando vif > 10
### Maroco (2003) diz o Variance Inflation Factor (VIF), deve apresentar valores inferiores a 5 para ausência de multicolinearidade.



## Interpretação do modelo
summary(mod)

# estatística F: comparação do modelo real com o modelo nulo (sem variáveis independentes). Então, só faz sentido usar o modelo real se ele for melhor que o modelo nulo. Para isso, o valor de p < 0,05.
# R-squared: porcentagem da variância que é explicada pelo modelo. O R-squared corrige pelo número de variáveis, o que permite comparar modelos com diferentes números de variáveis independentes. 

mod2 <- lm(idade ~ extr + cons, big_five_BR, na.action = na.omit)

summary(mod2)

### Se olhar o R-squared do mod e mod2, pode-se ter uma ideia de qual modelo é melhor.

## Obtenção dos coeficientes padronizados pelo pacote (QuantPsyc)
lm.beta(mod)
lm.beta(mod2)


## Obtenção do IC 95% para os coeficientes
confint(mod)
### para o valor de p ser significativo, o intervalo de confiança não pode incluir o zero. às vezes isso não funciona por causa do métdo de análise das distribuições.
confint(mod2)

# Comparação de modelos
## AIC e BIC - Comparação entre quaisquer modelos

AIC(mod, mod2)   
### quanto menor, melhor
### representam a variância não explicada pelo modelo
### para um modelo ser melhor que o outro, a diferença deve ser pelo menos 10.

BIC(mod,mod2) # Modelo Bayesiano, que funciona da mesma forma.

# Comparação de modelos aninhados (o modelo 2 é derivado do modelo 1)
anova(mod,mod2)
### o melhor modelo será o valor de RSS menor (residual sum of squares)


# Representação gráfica
graph <- scatterplot3d(big_five_BR$idade ~ big_five_BR$extr + big_five_BR$cons,
                       pch = 16, angle = 30, color = "steelblue", box = FALSE,
                       xlab = "Extroversão", ylab = "Conscienciosidade", zlab = "Idade")

graph$plane3d(mod2, col = "black", draw_polygon = TRUE)
```

### Exercícios sobre regressão linear múltipla

Realizar uma análise de regressão para verificar se os traços de personalidade e o raciocínio verbal predizem autoritarismo.

```{r include=FALSE}
rwas <- read.csv("rwas.csv", header = TRUE, sep = ",",stringsAsFactors = TRUE)

# Inspecionar o banco de dados
glimpse(rwas)

# Fazer uma cópia de segurança desse banco de dados.
rwas_copy <- rwas # cópia de segurança


# inverter itens negativos usando função recode() do expss
# itens já foram invertidos, por isso o código está desligado
# expss::recode(rwas[ ,c("TIPI2","TIPI6","TIPI8","TIPI9","TIPI10")]) <- c(1~7,2~6,3~5,4~4,5~3,6~2,7~1)

# Atribuição de labels aos itens do TIPI
# rwas <- apply_labels(rwas,
#                      TIPI1 = "Extraverted, enthusiastic",
#                      TIPI2 = "Critical, quarrelsome",
#                      TIPI3 = "Independable, self-disciplined",
#                      TIPI4 = "Anxious, easily upset",
#                      TIPI5 = "Open to new experiences, complex",
#                      TIPI6 = "Reserved, quiet",
#                      TIPI7 = "Sympathetic, warm",
#                      TIPI8 = "Disorganized, careless",
#                      TIPI9 = "Calm, emotionally stable",
#                      TIPI10 = "Conventional, uncreative")

fa_tipi <- rwas %>% dplyr::select(48:57) %>% fa(nfactors = 5, 
                                                cor = "cor",
                                                fm = "wls",
                                                rotate = "geominQ")

names(rwas)
rwas$extr <- rwas %>% dplyr::select("TIPI1","TIPI6") %>% rowMeans()
rwas$neur <- rwas %>% dplyr::select("TIPI2","TIPI7") %>% rowMeans()
rwas$amab <- rwas %>% dplyr::select("TIPI4","TIPI9") %>% rowMeans()
rwas$cons <- rwas %>% dplyr::select("TIPI3","TIPI8") %>% rowMeans()
rwas$aber <- rwas %>% dplyr::select("TIPI5","TIPI10") %>% rowMeans()

rwas$rv <- rwas %>% dplyr::select(58:62,64:65,67:68,70:73) %>% rowSums()

# Escala de autoritarismo de direita
rwas$auth <- rwas %>% dplyr::select(3:22) %>% rowSums()

# Seleção de participantes americanos para redução do df
rwas_us <- rwas %>% filter(IP_country == "US")

# rodando a regressão
glimpse(rwas_us)

mod_rwas_us <- lm(auth ~ extr+neur+amab+cons+aber+rv,
                  data=rwas_us,
                  na.action = na.omit)
summary(mod_rwas_us)

## Análise dos pressupostos
par(mfrow = c(2,2))
plot(mod_rwas_us)

### O primeiro gráfico permite avaliar a linearidade. A linha vermelha tem que estar aproximadamente horizontal para o modelo ser linear.
### O segundo gráfico permite verificar se os resíduos apresentam distribuição normal (Q-Q plot). No eixo y os resíduos encontrados e no eixo x os resíduos que seriam esperados caso a distribuição fosse de fato normal. O esperado é que os pontos caiam sobre a linha pontilhada
### O terceiro gráfico avalia homocedasticidade. Para que haja homocedasticidade os pontos têm que estar distribuídos aleatoriamente pelo retângulo do gráfico e não formando um triângulo. Ou seja, os resíduos têm que ser aleatórios e não correlacionados entre si.
### No quarto gráfico é possível verificar a existência de outliers e pontos influentes. Caso existam outliers haverá pontos para fora da linha pontilhada vermelha. Os resíduos padronizados devem estar entre -3 e +3 (eixo y).

par(mfrow_us = c(1,1))   # voltar para 1 gráfico por página.

## normalidade dos resíduos
options(scipen = 999)
shapiro.test(mod_rwas_us$residuals)

## Outliers nos resíduos
summary(rstandard(mod_rwas_us)) # os resultados devem estar entre -3 e +3

## Teste de Durbin-Watson
durbinWatsonTest(mod_rwas_us)   
### não há autocorrelação entre os resíduos quando o valor da estatística está próximo a 2 (entre 1,5 e 2,5, ou entre 1 e 3)

## Homocedasticidade (Breusch-Pagan) ou homogeneidade das variâncias
bptest(mod_rwas_us)   # o valor de p > 0,05 indica que há homocedasticidade


## Ausência de multicolinearidade

pairs.panels(rwas_us[,91:95]) # há multicolinearidade quando r > 0.9

vif(mod_rwas_us)
### há problema de multicolinearidade quando vif > 10



## Interpretação do modelo
summary(mod_rwas_us)

# estatística F: comparação do modelo real com o modelo nulo (sem variáveis independentes). Então, só faz sentido usar o modelo real se ele for melhor que o modelo nulo. Para isso, o valor de p < 0,05.
# R-squared: porcentagem da variância que é explicada pelo modelo. O R-squared corrige pelo número de variáveis, o que permite comparar modelos com diferentes números de variáveis independentes. 

mod2_rwas_us <- lm(auth ~ amab + cons + rv, rwas_us)

summary(mod2_rwas_us)

### Se olhar o R-squared do mod e mod2, pode-se ter uma ideia de qual modelo é melhor.

## Obtenção dos coeficientes padronizados pelo pacote (QuantPsyc)
lm.beta(mod_rwas_us)
lm.beta(mod2_rwas_us)

## Obtenção do IC 95% para os coeficientes
confint(mod2_rwas_us)
### para o valor de p ser significativo, o intervalo de confiança não pode incluir o zero. às vezes isso não funciona por causa do métdo de análise das distribuições.

# Comparação de modelos
## AIC e BIC - Comparação entre quaisquer modelos

AIC(mod_rwas_us, mod2_rwas_us)   
### quanto menor, melhor
### representam a variância não explicada pelo modelo
### para um modelo ser melhor que o outro, a diferença deve ser pelo menos 10.

BIC(mod_rwas_us, mod2_rwas_us) # Modelo Bayesiano, que funciona da mesma forma.

# Comparação de modelos aninhados (o modelo 2 é derivado do modelo 1)
anova(mod_rwas_us, mod2_rwas_us)
### o melhor modelo será o valor de RSS menor (residual sum of squares)

```

## Regressão logística

A regressão logística é mais apropriada quando se quer predizer uma variável dicotômica, ou as chances de que uma de duas categorias ocorram.
Por exemplo, predizer a existência de certa condição mental (sim ou não), ser aprovado numa prova (sim ou não), ser parte do grupo experimental de uma investigação (sim ou não), entre outras.
A regressão logística modela os dados por meio de uma curva sigmóide, em forma de S.
Vejamos.

### Pacotes necessários

```{r}
pacman::p_load(dplyr,car,MASS,DescTools,QuantPsyc,ggplot2)
```

Para fazer a análise, usaremos o banco de dados rwas.
Abaixo estão os códigos para as transformações das variáveis.

```{r}
# criar arquivo para teste das análises

rwas$education <- as.factor(rwas$education)
levels(rwas$education) <- c(NA,"Less than high school","High school","University degree","Graduate degree")

rwas$urban <- as.factor(rwas$urban)
levels(rwas$urban) <- c(NA,"Rural (country side)","Suburban","Urban (town, city)")
count(rwas,urban)

rwas$gender <- as.factor(rwas$gender)
levels(rwas$gender) <- c(NA,"Male","Female","Other")
count(rwas,gender)

expss::recode(rwas$engnat) <- c(0~NA,1~1,2~0)
rwas$engnat <- as.factor(rwas$engnat)
levels(rwas$engnat) <- c("No","Yes",NA)
count(rwas,engnat)

# count(rwas,age) %>% knitr::kable()
rwas$age[rwas$age > 100] <- NA

rwas$religion <- as.factor(rwas$religion)
levels(rwas$religion) <- c(NA,"Agnostic","Atheist","Buddhist","Christian (Catholic)","Christian (Mormon)",
                            "Christian (Protestant)","Christian (Other)","Hindu","Jewish","Muslim","Sikh","Other")
count(rwas,religion)

rwas$orientation <- as.factor(rwas$orientation)
levels(rwas$orientation) <- c(NA,"Heterosexual","Arab","Black","Indigenous Australian","Native American or White","Other")
count(rwas,orientation)

rwas$race <- as.factor(rwas$race)
levels(rwas$race) <- c(NA,"Asian","Bisexual","Homosexual","Asexual","Other")
count(rwas,race)

expss::recode(rwas$voted) <- c(0~NA,1~1,2~0)
rwas$voted <- as.factor(rwas$voted)
levels(rwas$voted) <- c("No","Yes",NA)
count(rwas,voted)

rwas$married <- as.factor(rwas$married)
levels(rwas$married) <- c(NA,"Never married","Currently married","Previously married")
count(rwas,married)

glimpse(rwas)

# cópia de segurança do arquivo base
rwas1 <- rwas
```

Nessa análise estamos tentando predizer se uma pessoa é ateia ou cristã-católica a partir dos cinco grandes fatores de personalidade e da variável sexo (masculino e feminino).
Iremos testar dois modelos.
O primeiro com todas as variáveis e o segundo somente com as variáveis que se mostrarem significativas no primeiro modelo.
Para poder comparar esses modelos é necessário obter um banco de dados de igual comprimento nos dois modelos e isso é dificultado pelos NA's nas variáveis preditoras.
Por isso, vamos criar um subset do banco de dados rwas, que esteja livre de NA's.

# Análise de Pressupostos

```{r}
# Criar variável em que Atheist=0, Christian(Catholic)=1 e os demais são NA
# A ideia é contrapor ateus e católicos. 
# Pergunta: traços de personalidade conseguem predizer se uma pessoa é ateia ou religiosa.
rwas <- rwas %>% mutate(believer = ifelse(religion == "Atheist",0,
                                          ifelse(religion == "Christian (Catholic)",1,NA)))
# transformar variável believer em fator
rwas$believer <- as.factor(rwas$believer)
levels(rwas$believer) <- c("Atheist","Christian (Catholic)",NA)

# criar variável sex a partir de gender, para transformá-la numa variável com apenas duas categorias: masculino e feminino

rwas$sex <- rwas$gender
expss::recode(rwas$sex) <- c("Male" ~ "Male", "Female" ~ "Female", "Other" ~ NA)
levels(rwas$sex) <- c("Male","Female",NA)

# Selecionar um subset do rwas sem nenhum NA
# Isso é necessário especialmente quando se deseja comparar modelos, que têm que ter a mesma extensão.
rwas_nona <- rwas[which(complete.cases(rwas[,c('believer', 'extr', 'neur', 'amab', 'cons', 'aber', "sex")])),]

# Análise das frequências em cada categoria da VD
table(rwas_nona$believer)
summary(rwas_nona)

# Checar categoria de referência das variáveis categóricas
levels(rwas_nona$believer) # Atheist é a categoria de referência
levels(rwas_nona$sex)      # Male é a categoria de referência

# Pressupostos
## 1. Variàvel dependente dicotômica com categorias mutuamente excludentes
## 2. Independência das observações 
## 3. Ausência de outliers / pontos de alavancagem

mod_rlog1 <- glm(believer ~ extr+neur+cons+amab+aber+sex,
                 family = "binomial"(link = "logit"),
                 data = rwas_nona,
                 na.action = na.omit)
summary(mod_rlog1)
plot(mod_rlog1, which = 5)
# verificar se os pontos se concentram dentro dos limites da linha tracejada (cook's distance)

summary(stdres(mod_rlog1)) 
# o resultados deve estar entre -3 e 3.

## 4. Ausência de multicolinearidade
pairs.panels(rwas[,c("extr","neur","amab","cons","aber")])
## As correlações devem estar abaixo de 0,9 (alguns autores falam em <0.8)

vif(mod_rlog1)
## ocorre problema de multicolinearidade quanto vif>10


```

## Rodando os modelos

```{r}
# MODELO 1
mod_rlog1 <- glm(believer ~ extr+neur+cons+amab+aber+sex,
                 family = "binomial"(link = "logit"),
                 data = rwas_nona,
                 na.action = na.omit)

## Overall effects
Anova(mod_rlog1, type = "II", test.statistic = "Wald") 
### Obs.: Anova, com A maiúscula, é do pacote car.
### Obs.: anova, com a minúscula, é do pacote stats, da base do R.

summary(mod_rlog1)

## razões de chances (usando o erro padrão)
round(exp(cbind(OR = coef(mod_rlog1), confint.default(mod_rlog1))),digits = 3)

# MODELO 2 - somente com as variáveis preditoras significativas no MODELO 1
mod_rlog2 <- glm(believer ~ extr+neur+cons+aber, 
                 family = "binomial"(link = "logit"),
                 data = rwas_nona,
                 na.action = na.omit)

## Overall effects - MODELO 2
Anova(mod_rlog2, type = "II", test.statistic = "Wald")

summary(mod_rlog2)

## Razões de chances (usando o erro padrão)
round(exp(cbind(OR = coef(mod_rlog2), confint.default(mod_rlog2))),digits = 3)

# COMPARAÇÃO ENTRE MODELOS 1 E 2

## AIC e BIC

AIC(mod_rlog1,mod_rlog2)
BIC(mod_rlog1,mod_rlog2)

## Qui-quadrado

anova(mod_rlog2,mod_rlog1, test = "Chisq") 
```

# Análise fatorial exploratória

```{r}
# ANÁLISE FATORIAL DO TIPI

## Determinação do número de fatores a serem retidos
rwas %>% dplyr::select(48:57) %>% scree(pc = FALSE)


## AFE
fa_tipi <- rwas %>% dplyr::select(48:57) %>% fa(nfactors = 5, 
                                                cor = "cor",
                                                fm = "wls",
                                                rotate = "geominQ")

# ANÁLISE FATORIAL DO VCL

## Determinação do número de fatores a serem retidos
rwas %>% dplyr::select(58:73) %>% scree(pc = FALSE)

## AFE
fa_rv <- rwas %>% dplyr::select(58:73) %>% fa(nfactors = 2,
                                              cor = "tet",
                                              fm = "wls")
summary(fa_rv)
fa_rv$Structure

# OBS: O resultados com dois fatores é interessante porque o segundo fator é exatamente com os itens 6, 9 e 12, que não são palavras reais. 

# Eliminação de itens que apresentaram cargas mais baixas.
fa_rv1 <- rwas %>% dplyr::select(58:62,64:65,67:68,70:73) %>% fa(nfactors = 1,
                                              cor = "tet",
                                              fm = "wls")

summary(fa_rv1)
fa_rv1$Structure
```

# Análises de efeitos de pertencimento a grupos

Em muitas pesquisas, o interesse recai sobre os efeitos de grupo.
Nesses casos, investiga-se se o fato das pessoas perteceram a um grupo produz algum efeito em alguma variável psicológica.
Por exemplo, qual é o efeito de sexo (masculino ou feminino) na variável inteligência?
Qual é o efeito de um programa de desenvolvimento da inteligência emocional (grupos controle e experimental) sobre a qualidade de vida?
Qual o efeito do país de origem (A, B, C) no desempenho escolar?
As análises estatísticas que normalmente são usadas nesses estudos são as seguintes:

Teste t Análise de variância de duas vias (ANOVA) Análise de varância univariada Análise de variância multivariada (MANOVA) - Anova Fatorial Análise de Covariância (ANCOVA) Análise Multivariada de Covariância (MANCOVA) Análise de variância por medidas repetidas

## Teste t

Quando queremos comparar uma variável do nosso banco de dados com os dados constantes na literatura (por exemplo, as pontuações em depressão da nossa amostra com a média da população), usamos o **teste t para uma amostra**.
Como exemplo, vamos usar o banco de dados `big_five_BR`, para investigar se as pontuações em neuroticismo dos brasileiros é significativamente diferentes da média encontrada nos diversos países em que a escala foi aplicada.
Para isso, começamos investigando se a distribuição das pontuações é ao menos próxima da distribuição normal.

### Análise do pressuposto de normalidade

O ideal é empregar o teste de Shapiro-Wilk para a verificação da normalidade da variável que se quer testar.
No entanto, esse teste, geralmente, resulta em diferença significativa, mesmo quando a distribuição é muito próxima da normal.
Por isso, costuma-se usar parâmetros um pouco mais flexíveis, que são os índices de assimetria e curtose.

```{r}
#shapiro.test(dataset$neur)

skew(big_five_BR$neur,na.rm = TRUE)
kurtosi(big_five_BR$neur,na.rm = TRUE)
```

Então, podemos considerar que os dados são próximos da distribuição normal pois, os dados de assimetria e curtose estão dentro do intervalo de -0,5 e 0,5 (Maroco, 2003).
Assim, prosseguimos com a análise e vamos calcular as médias da amostra completa (banco de dados `big_five`), que servirá de referência.

### Média da amostra completa (referência)

```{r}
# seleção de um subset do datarame big_five somente com os participantes NÃO-BRASILEIROS na variável neur 
média_neur <- big_five %>% 
  filter(!país == "BR") %>% 
  dplyr::select("neur")

# cálculo da média dos participantes NÃO-BRASILEIROS em neur
# Esse resultado será utilizado como referência no t-teste
round(mean(média_neur$neur, na.rm = TRUE),digits = 2)

```

## Teste-t para uma amostra

```{r}
t.test(                # t.test é o comando do stats
  big_five_BR$neur,    # localização da variável neur em brasileiros
  mu = 3.09)           # valor de referência, calculado anteriormente

```

O resultado foi estatísticamente significativo (p \< 0,05), indicando que a média dos brasileiros em neuroticismo é maior do que a média de outros países que compõem a amostra.

### Representação Gráfica

```{r}
big_five %>% mutate(Brasil = ifelse(país == "BR","BR","OU")) %>% 
  ggplot(aes(x = Brasil, y = neur)) +
  geom_boxplot(color = "black", fill = "#74c69d") +
  labs(title = "Média de Neuroticismo: Brasil x Mundo",
       x = "País",
       y = "Neuroticismo")
```

## Teste-t para amostras independentes

Essa análise estatística se aplica à comparação das médias de dois grupos em que os participantes ou estão em um grupo ou estão no outro, não sendo possível estar nos dois grupos ao mesmo tempo.
Por isso a denominação de **amostras independentes**.
Para isso, vamos usar o dataframe big_five_BR e analisar o efeito de gênero (sexo, na verdade, pois só consideraremos as categorias **masculino** e **feminino**) nos cinco grandes fatores de personalidade.

### Preparação do banco de dados e carregamento dos pacotes

Para a realização dessa análise vamos usar os pacotes `RVAideMemoire` e `car`.
O `car` já está instalado e foi ativado em análises anteriores.
O `RVAideMemoire` será empregado apenas em poucas análises, então não precisamos carregar o pacote (para não sobrecarregar o sistema), mas apenas chamar a função desejada.
Então, temos que preparar a variável gênero do dataframe big_five_BR, que contem três categorias (masculino, feminino e outro).
Como o teste-t só funciona para duas categorias e a categoria gênero apresenta apenas duas observações "outro", vamos transformar essas duas observações em NAs.

```{r}
# primeiro passo: trasnformar a categoria "outros" em NA
big_five_BR$gênero[big_five_BR$gênero == "Outro"] <- NA
```

### Análise dos pressupostos

```{r}
# verificação da normalidade dos dados, separado por grupos.
# vamos usar o pacote RVAideMemoire

## RVAideMemoire::byf.shapiro(formula = extr ~ gênero, data = big_five_nona)
### a função anterior não está funcionando e não consegui descobrir por quê.
### então, fui para a observação dos índices de assimetria e curtose

### skewness()

skew(big_five_BR$extr, na.rm = TRUE)
skew(big_five_BR$neur, na.rm = TRUE)
skew(big_five_BR$amab, na.rm = TRUE)
skew(big_five_BR$cons, na.rm = TRUE)
skew(big_five_BR$aber, na.rm = TRUE)


### kurtosis()

kurtosi(big_five_BR$extr, na.rm = TRUE)
kurtosi(big_five_BR$neur, na.rm = TRUE)
kurtosi(big_five_BR$amab, na.rm = TRUE)
kurtosi(big_five_BR$cons, na.rm = TRUE)
kurtosi(big_five_BR$aber, na.rm = TRUE)

# verificação da homogeneidade das variâncias
# Teste de Levene usando o pacote car

leveneTest(extr ~ gênero, big_five_BR, center=mean)
leveneTest(neur ~ gênero, big_five_BR, center=mean)
leveneTest(amab ~ gênero, big_five_BR, center=mean)
leveneTest(cons ~ gênero, big_five_BR, center=mean)
leveneTest(aber ~ gênero, big_five_BR, center=mean)

## OBS: Por default, o teste realizado pelo pacote car tem como base a mediana, que é mais robusto, mas, para ficar igual ao SPSS, mudamos para a média, por isso o argumento center=mean.
## Em todas as variáveis as variâncias foram homogêneas

t_extr <- t.test(extr ~ gênero, big_five_BR, var.equal = TRUE)
t_neur <- t.test(neur ~ gênero, big_five_BR, var.equal = TRUE)
t_amab <- t.test(amab ~ gênero, big_five_BR, var.equal = TRUE)
t_cons <- t.test(cons ~ gênero, big_five_BR, var.equal = TRUE)
t_aber <- t.test(aber ~ gênero, big_five_BR, var.equal = TRUE)

t_extr$
```

### Apresentação dos resultados em uma tabela

```{r}
data.frame(Variável = c("Extroversão","Neuroticismo","Amabilidade",
                        "Conscienciosidade","Abertura"),
           t = c(round(t_extr$statistic,digits = 3),
                 round(t_neur$statistic,digits = 3),
                 round(t_amab$statistic,digits = 3),
                 round(t_cons$statistic,digits = 3),
                 round(t_aber$statistic,digits = 3)),
           gl = c(t_extr$parameter,
                  t_neur$parameter,
                  t_amab$parameter,
                  t_cons$parameter,
                  t_aber$parameter),
           p = c(round(t_extr$p.value,digits = 3),
                 round(t_neur$p.value,digits = 3),
                 round(t_amab$p.value,digits = 3),
                 round(t_cons$p.value,digits = 3),
                 round(t_aber$p.value,digits = 3))) %>% pander::pander()

```

Juntamente com esse resultado, é necessário apresentar as estatísticas descritivas.
Então, a tabela poderia ficar assim.

```{r}

## Usando a função tableby do pacote arsenal
tableby(gênero ~ extr + neur + amab + cons + aber, data = big_five_BR, test = FALSE) %>% summary(text = TRUE)
```

### Representação gráfica

```{r}
# usando o graphics (base do R)
boxplot(amab ~ gênero, big_five_BR, ylab = "Amabilidade", xlab = "Sexo")

# usando o ggplot

```

## Teste-t para amostras pareadas

Muitas vezes, os pesquisadores estão interessados em comparar o mesmo grupo de pessoas em duas situações diferentes, como por exemplo, antes e após alguma intervenção (pré e pós-teste).
Como o grupo de pessoas é o mesmo, diz-se que o teste-t é para **amostras pareadas**.
Para realizar essa análise, vamos utilizar um **banco de dados fictício** que contém duas supostas medidas de habilidades em leitura, uma realizada antes de um programa de intervenção para estimulação da leitura, e uma realizada após o programa.

```{r}
# Criação de um dataframe para análise de dados pareados
df <- data.frame(id = paste("s",1:30,sep=""),
                 pre_teste = rnorm(30, mean = 5.14, sd = 1.23),
                 pos_teste = rnorm(30, mean = 6.78, sd = 0.93))
```

### Análise dos pressupostos

```{r}
# verificação da normalidade
## O pressuposto é que a diferença entre as variáveis seja normal
## então, o primeiro passo é calcular as diferenças e inserir como uma variável no dataframe df

df$dif <- df$pos_teste - df$pre_teste

### teste de Shapiro-Wilk para normalidade
shapiro.test(df$dif)

### Testes de assimetria e curtose
skew(df$dif)
kurtosi(df$dif)
```

### Teste-t para amostras pareadas

```{r}
t_par <- t.test(df$pos_teste,df$pre_teste,paired = TRUE)
```

### Apresentação dos resultados em uma tabela

```{r}
summary(df$pre_teste)
summary(df$pos_teste)

desc_ <- describe(df$pre_teste)

data.frame(Variáves = c("Pré-teste",
                          "Pós-teste"),
           Média = c(round(mean(df$pre_teste,na.rm=TRUE),digits=2),
                     round(mean(df$pos_teste,na.rm=TRUE),digits=2)),
           "Desv. Padrão" = c(round(sd(df$pre_teste,na.rm=TRUE),digits=2),
                              round(sd(df$pos_teste,na.rm=TRUE),digits=2))) %>% 
  pander()
```

### Representação gráfica

```{r}
par(mfrow=c(1,2))
boxplot(df$pre_teste, ylab="Leitura - Pré-teste", xlab="Pré-Teste")
boxplot(df$pos_teste, ylab="Leitura - Pós-teste", xlab="Pós-Teste")

par(mfrow=c(1,1))
```

## Análise de Variância

O teste-t apresenta uma limitação, que é a de só conseguir comparar duas categorias.
Para superar essa limitação e podermos comparar mais de duas categorias de uma variável é preciso utilizar uma Análise de Variância (ANOVA).

### ANOVA de uma via

Para realizar essa análise vamos usar o dataframe `dataset` para verificar se há efeito da nacionalidade (Brasil, Portugal e Espanha) sobre a medida de depressão realizada pelo Beck Depression Inventory (BDI).

```{r}
# seleção de um subset do banco de dados com 
nrow(rwas)


```

### Verificação dos pressupostos

```{r}
# A maioria dos autores recomenda que a normalidade seja avaliada por grupo e não como um todo.

byf.shapiro(rv ~ education, rwas)
# Os resultados, como de costume, deram significativos, ou seja, diferente de uma distribuição normal. Por isso, vamos usar um critério mais permissivo: as análises de assimetria e curtose.

rwas %>% 
  filter(education=="Less than high school") %>% 
  dplyr::select("auth") %>% 
  skew()
rwas %>% filter(education=="High school") %>% dplyr::select("auth") %>% skew()
rwas %>% filter(education=="University degree") %>% dplyr::select("auth") %>% skew()
rwas %>% filter(education=="Graduate degree") %>% dplyr::select("auth") %>% skew()

rwas %>% filter(education=="Less than high school") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="High school") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="University degree") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="Graduate degree") %>% dplyr::select("auth") %>% kurtosi()

# verificação da homogeneidade das variâncias
car::leveneTest(auth ~ education, rwas, center = mean)

# verificação dapresença de outliers

## usando boxplot
boxplot(auth ~ education, rwas, ylab = "autoritarismo", xlab = "escolaridade")

## usando identify_outliers
rwas %>% 
  dplyr::select(education, auth) %>% 
  dplyr::group_by(education) %>% 
  rstatix::identify_outliers(auth) %>% kable()

```

### Realização da ANOVA de uma via

```{r}

# Criação do modelo
anova_auth <- aov(auth ~ education, rwas)

# visualização dos resultados
summary(anova_auth)

# Testes de post-hoc
# post-hocs permitidos: "hsd", "bonferroni", "lsd", "scheffe", "duncan"

```
