---
title: "Estatística no R"
author: "Maurício Bueno"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Análises dos efeitos do pertencimento a grupos

Em muitas pesquisas, o interesse recai sobre os efeitos de grupo.
Nesses casos, investiga-se se o fato das pessoas perteceram a um grupo produz algum efeito em alguma variável psicológica.
Por exemplo, qual é o efeito de sexo (masculino ou feminino) na variável inteligência?
Qual é o efeito de um programa de desenvolvimento da inteligência emocional (grupos controle e experimental) sobre a qualidade de vida?
Qual o efeito do país de origem (A, B, C) no desempenho escolar?
As análises estatísticas que normalmente são usadas nesses estudos são as seguintes:

Teste t Análise de variância de duas vias (ANOVA) Análise de varância univariada Análise de variância multivariada (MANOVA) - Anova Fatorial Análise de Covariância (ANCOVA) Análise Multivariada de Covariância (MANCOVA) Análise de variância por medidas repetidas

# Teste t

Quando queremos comparar uma variável do nosso banco de dados com os dados constantes na literatura (por exemplo, as pontuações em depressão da nossa amostra com a média da população), usamos o **teste t para uma amostra**.
Como exemplo, vamos usar o banco de dados `big_five_BR`, para investigar se as pontuações em neuroticismo dos brasileiros é significativamente diferentes da média encontrada nos diversos países em que a escala foi aplicada.
Para isso, começamos investigando se a distribuição das pontuações é ao menos próxima da distribuição normal.

# Teste-t para uma amostra

### Análise do pressuposto de normalidade

O ideal é empregar o teste de Shapiro-Wilk para a verificação da normalidade da variável que se quer testar.
No entanto, esse teste, geralmente, resulta em diferença significativa, mesmo quando a distribuição é muito próxima da normal.
Por isso, costuma-se usar parâmetros um pouco mais flexíveis, que são os índices de assimetria e curtose.

```{r}
#shapiro.test(dataset$neur)

skew(big_five_BR$neur,na.rm = TRUE)
kurtosi(big_five_BR$neur,na.rm = TRUE)
```

Então, podemos considerar que os dados são próximos da distribuição normal pois, os dados de assimetria e curtose estão dentro do intervalo de -0,5 e 0,5 (Maroco, 2003).
Assim, prosseguimos com a análise e vamos calcular as médias da amostra completa (banco de dados `big_five`), que servirá de referência.

### Média da amostra completa (referência)

```{r}
# seleção de um subset do datarame big_five somente com os participantes NÃO-BRASILEIROS na variável neur 
média_neur <- big_five %>% 
  filter(!país == "BR") %>% 
  dplyr::select("neur")

# cálculo da média dos participantes NÃO-BRASILEIROS em neur
# Esse resultado será utilizado como referência no t-teste
round(mean(média_neur$neur, na.rm = TRUE),digits = 2)

```

### Teste-t para uma amostra

```{r}
t.test(                # t.test é o comando do stats
  big_five_BR$neur,    # localização da variável neur em brasileiros
  mu = 3.09)           # valor de referência, calculado anteriormente

```

O resultado foi estatísticamente significativo (p \< 0,05), indicando que a média dos brasileiros em neuroticismo é maior do que a média de outros países que compõem a amostra.

### Representação Gráfica

```{r}
big_five %>% mutate(Brasil = ifelse(país == "BR","BR","OU")) %>% 
  ggplot(aes(x = Brasil, y = neur)) +
  geom_boxplot(color = "black", fill = "#74c69d") +
  labs(title = "Média de Neuroticismo: Brasil x Mundo",
       x = "País",
       y = "Neuroticismo")
```

# Teste-t para amostras independentes

Essa análise estatística se aplica à comparação das médias de dois grupos em que os participantes ou estão em um grupo ou estão no outro, não sendo possível estar nos dois grupos ao mesmo tempo.
Por isso a denominação de **amostras independentes**.
Para isso, vamos usar o dataframe big_five_BR e analisar o efeito de gênero (sexo, na verdade, pois só consideraremos as categorias **masculino** e **feminino**) nos cinco grandes fatores de personalidade.

### Preparação do banco de dados e carregamento dos pacotes

Para a realização dessa análise vamos usar os pacotes `RVAideMemoire` e `car`.
O `car` já está instalado e foi ativado em análises anteriores.
O `RVAideMemoire` será empregado apenas em poucas análises, então não precisamos carregar o pacote (para não sobrecarregar o sistema), mas apenas chamar a função desejada.
Então, temos que preparar a variável gênero do dataframe big_five_BR, que contem três categorias (masculino, feminino e outro).
Como o teste-t só funciona para duas categorias e a categoria gênero apresenta apenas duas observações "outro", vamos transformar essas duas observações em NAs.

```{r}
# primeiro passo: trasnformar a categoria "outros" em NA
big_five_BR$gênero[big_five_BR$gênero == "Outro"] <- NA
```

### Análise dos pressupostos

```{r}
# verificação da normalidade dos dados, separado por grupos.
# vamos usar o pacote RVAideMemoire

## RVAideMemoire::byf.shapiro(formula = extr ~ gênero, data = big_five_nona)
### a função anterior não está funcionando e não consegui descobrir por quê.
### então, fui para a observação dos índices de assimetria e curtose

### skewness()

skew(big_five_BR$extr, na.rm = TRUE)
skew(big_five_BR$neur, na.rm = TRUE)
skew(big_five_BR$amab, na.rm = TRUE)
skew(big_five_BR$cons, na.rm = TRUE)
skew(big_five_BR$aber, na.rm = TRUE)


### kurtosis()

kurtosi(big_five_BR$extr, na.rm = TRUE)
kurtosi(big_five_BR$neur, na.rm = TRUE)
kurtosi(big_five_BR$amab, na.rm = TRUE)
kurtosi(big_five_BR$cons, na.rm = TRUE)
kurtosi(big_five_BR$aber, na.rm = TRUE)

# verificação da homogeneidade das variâncias
# Teste de Levene usando o pacote car

leveneTest(extr ~ gênero, big_five_BR, center=mean)
leveneTest(neur ~ gênero, big_five_BR, center=mean)
leveneTest(amab ~ gênero, big_five_BR, center=mean)
leveneTest(cons ~ gênero, big_five_BR, center=mean)
leveneTest(aber ~ gênero, big_five_BR, center=mean)

## OBS: Por default, o teste realizado pelo pacote car tem como base a mediana, que é mais robusto, mas, para ficar igual ao SPSS, mudamos para a média, por isso o argumento center=mean.
## Em todas as variáveis as variâncias foram homogêneas

t_extr <- t.test(extr ~ gênero, big_five_BR, var.equal = TRUE)
t_neur <- t.test(neur ~ gênero, big_five_BR, var.equal = TRUE)
t_amab <- t.test(amab ~ gênero, big_five_BR, var.equal = TRUE)
t_cons <- t.test(cons ~ gênero, big_five_BR, var.equal = TRUE)
t_aber <- t.test(aber ~ gênero, big_five_BR, var.equal = TRUE)

t_extr$
```

### Apresentação dos resultados em uma tabela

```{r}
data.frame(Variável = c("Extroversão","Neuroticismo","Amabilidade",
                        "Conscienciosidade","Abertura"),
           t = c(round(t_extr$statistic,digits = 3),
                 round(t_neur$statistic,digits = 3),
                 round(t_amab$statistic,digits = 3),
                 round(t_cons$statistic,digits = 3),
                 round(t_aber$statistic,digits = 3)),
           gl = c(t_extr$parameter,
                  t_neur$parameter,
                  t_amab$parameter,
                  t_cons$parameter,
                  t_aber$parameter),
           p = c(round(t_extr$p.value,digits = 3),
                 round(t_neur$p.value,digits = 3),
                 round(t_amab$p.value,digits = 3),
                 round(t_cons$p.value,digits = 3),
                 round(t_aber$p.value,digits = 3))) %>% pander::pander()

```

Juntamente com esse resultado, é necessário apresentar as estatísticas descritivas.
Então, a tabela poderia ficar assim.

```{r}

## Usando a função tableby do pacote arsenal
tableby(gênero ~ extr + neur + amab + cons + aber, data = big_five_BR, test = FALSE) %>% summary(text = TRUE)
```

### Representação gráfica

```{r}
# usando o graphics (base do R)
boxplot(amab ~ gênero, big_five_BR, ylab = "Amabilidade", xlab = "Sexo")

# usando o ggplot

```

# Teste-t para amostras pareadas

Muitas vezes, os pesquisadores estão interessados em comparar o mesmo grupo de pessoas em duas situações diferentes, como por exemplo, antes e após alguma intervenção (pré e pós-teste).
Como o grupo de pessoas é o mesmo, diz-se que o teste-t é para **amostras pareadas**.
Para realizar essa análise, vamos utilizar um **banco de dados fictício** que contém duas supostas medidas de habilidades em leitura, uma realizada antes de um programa de intervenção para estimulação da leitura, e uma realizada após o programa.

```{r}
# Criação de um dataframe para análise de dados pareados
df <- data.frame(id = paste("s",1:30,sep=""),
                 pre_teste = rnorm(30, mean = 5.14, sd = 1.23),
                 pos_teste = rnorm(30, mean = 6.78, sd = 0.93))
```

### Análise dos pressupostos

```{r}
# verificação da normalidade
## O pressuposto é que a diferença entre as variáveis seja normal
## então, o primeiro passo é calcular as diferenças e inserir como uma variável no dataframe df

df$dif <- df$pos_teste - df$pre_teste

### teste de Shapiro-Wilk para normalidade
shapiro.test(df$dif)

### Testes de assimetria e curtose
skew(df$dif)
kurtosi(df$dif)
```

### Teste-t para amostras pareadas

```{r}
t_par <- t.test(df$pos_teste,df$pre_teste,paired = TRUE)
```

### Apresentação dos resultados em uma tabela

```{r}
summary(df$pre_teste)
summary(df$pos_teste)

desc_ <- describe(df$pre_teste)

data.frame(Variáves = c("Pré-teste",
                          "Pós-teste"),
           Média = c(round(mean(df$pre_teste,na.rm=TRUE),digits=2),
                     round(mean(df$pos_teste,na.rm=TRUE),digits=2)),
           "Desv. Padrão" = c(round(sd(df$pre_teste,na.rm=TRUE),digits=2),
                              round(sd(df$pos_teste,na.rm=TRUE),digits=2))) %>% 
  pander()
```

### Representação gráfica

```{r}
par(mfrow=c(1,2))
boxplot(df$pre_teste, ylab="Leitura - Pré-teste", xlab="Pré-Teste")
boxplot(df$pos_teste, ylab="Leitura - Pós-teste", xlab="Pós-Teste")

par(mfrow=c(1,1))
```

# Análise de Variância

O teste-t apresenta uma limitação importante, que é a de só conseguir comparar **duas** categorias de uma variável.
Para superar essa limitação e podermos comparar mais de duas categorias de uma variável é preciso utilizar uma Análise de Variância (ANOVA).

# ANOVA de uma via

Para realizar essa análise vamos usar o dataframe `dataset` para verificar se há efeito da nacionalidade (Brasil, Portugal e Espanha) sobre a medida de depressão realizada pelo Beck Depression Inventory (BDI).

```{r}
# seleção de um subset do banco de dados com 
nrow(rwas)


```

### Verificação dos pressupostos

```{r}
# A maioria dos autores recomenda que a normalidade seja avaliada por grupo e não como um todo.

byf.shapiro(rv ~ education, rwas)
# Os resultados, como de costume, deram significativos, ou seja, diferente de uma distribuição normal. Por isso, vamos usar um critério mais permissivo: as análises de assimetria e curtose.

rwas %>% 
  filter(education=="Less than high school") %>% 
  dplyr::select("auth") %>% 
  skew()
rwas %>% filter(education=="High school") %>% dplyr::select("auth") %>% skew()
rwas %>% filter(education=="University degree") %>% dplyr::select("auth") %>% skew()
rwas %>% filter(education=="Graduate degree") %>% dplyr::select("auth") %>% skew()

rwas %>% filter(education=="Less than high school") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="High school") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="University degree") %>% dplyr::select("auth") %>% kurtosi()
rwas %>% filter(education=="Graduate degree") %>% dplyr::select("auth") %>% kurtosi()

# verificação da homogeneidade das variâncias
car::leveneTest(auth ~ education, rwas, center = mean)

# verificação dapresença de outliers

## usando boxplot
boxplot(auth ~ education, rwas, ylab = "autoritarismo", xlab = "escolaridade")

## usando identify_outliers
rwas %>% 
  dplyr::select(education, auth) %>% 
  dplyr::group_by(education) %>% 
  rstatix::identify_outliers(auth) %>% kable()

```

### Realização da ANOVA de uma via

```{r}

# Criação do modelo
anova_auth <- aov(auth ~ education, rwas)

# visualização dos resultados
summary(anova_auth)

# Testes de post-hoc
# post-hocs permitidos: "hsd" (Tukey's HSD), "bonferroni", "lsd", "scheffe", "duncan"
DescTools::PostHocTest(anova_auth, method = "hsd", conf.level = 0.95)
```

### Apresentação dos dados em tabela

```{r}
one_way_anova <- arsenal::tableby(education ~ auth, test = FALSE, rwas)

summary(one_way_anova,text=TRUE)
```
